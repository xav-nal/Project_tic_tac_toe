{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tic_env import TictactoeEnv, OptimalPlayer\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "list_of_action = {\n",
    "    0: (0,0),\n",
    "    1: (0,1),\n",
    "    2: (0,2),\n",
    "    3: (1,0),\n",
    "    4: (1,1),\n",
    "    5: (1,2),\n",
    "    6: (2,0),\n",
    "    7: (2,1),\n",
    "    8: (2,2)\n",
    "}\n",
    "\n",
    "rev_action = {\n",
    "    (0,0) :0,\n",
    "    (0,1) :1,\n",
    "    (0,2) :2,\n",
    "    (1,0) :3,\n",
    "    (1,1) :4,\n",
    "    (1,2) :5,\n",
    "    (2,0) :6,\n",
    "    (2,1) :7,\n",
    "    (2,2) :8\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_aval_actions(state_of_game,act):\n",
    "  possible_actions = []\n",
    "  for i in range(9):\n",
    "    if state_of_game[act[i]] == 0:\n",
    "      possible_actions.append(i)\n",
    "  return possible_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, in_features, outputs, action_list):\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        self.action_list = action_list\n",
    "        #print('input size',in_features )\n",
    "        \n",
    "        \n",
    "        self.head1 = nn.Linear(in_features, 128)\n",
    "        self.head2 = nn.Linear(128,128)\n",
    "        self.outputlayer = nn.Linear(128,outputs)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        #print('input x', x.shape, type(x))\n",
    "        #print('x reshape',x.reshape(x.shape(0),-1))\n",
    "        Batch_size,_,_,_ = x.shape\n",
    "        \n",
    "        #print('x reshape',x.reshape(Batch_size,-1).shape)\n",
    "        \n",
    "        x = F.relu(self.head1(torch.Tensor(x).reshape(Batch_size,-1)))\n",
    "        x = F.relu(self.head2(x))\n",
    "        x = self.outputlayer(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def act(self, state):\n",
    "        state_tensor = torch.as_tensor(state, dtype=torch.float32)\n",
    "        #print('----------------------------------------------------------')\n",
    "        #print('act', state_tensor.shape, state_tensor.unsqueeze(-1).shape )\n",
    "        q_values = self.forward(state_tensor.unsqueeze(0))\n",
    "        #possible_q_values = mask_possible_action*q_values\n",
    "        #print('possible_q_values',possible_q_values)\n",
    "        \n",
    "        \n",
    "        max_q_idx = torch.argmax(q_values, dim=1)[0]\n",
    "        max_q_idx_item = max_q_idx.detach().item()\n",
    "        #print('max_q_idx_item', max_q_idx_item, type(max_q_idx_item))\n",
    "        #print('action list', self.action_list)\n",
    "        #print('rev_action',rev_action)\n",
    "        move = self.action_list[max_q_idx_item]\n",
    "        \n",
    "        action_idx = rev_action[move]\n",
    "        \n",
    "        return action_idx\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE_FREQ = 500\n",
    "\n",
    "number_of_actions = 9\n",
    "state_features = 18\n",
    "\n",
    "\n",
    "env = TictactoeEnv()\n",
    "replay_buffer = deque(maxlen=BUFFER_SIZE)\n",
    "rew_buffer = deque([0.0], maxlen=10)\n",
    "\n",
    "episode_reward = 0.0\n",
    "\n",
    "#initialization network\n",
    "policy_net = DQN(state_features, number_of_actions,list_of_action).to(\"cpu\")\n",
    "target_net = DQN(state_features, number_of_actions,list_of_action).to(\"cpu\")\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "#target_net.eval()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_state(grid, agent_tag):\n",
    "    #print('Player',agent_tag,'grid',grid)\n",
    "    #print('grid', type(grid))\n",
    "    grid_tensor = torch.as_tensor(grid, dtype=torch.float32)\n",
    "    x_state = torch.zeros((3,3,2))\n",
    "    if agent_tag == 'X':\n",
    "        x_state[:,:,0] = torch.eq(grid_tensor,1).int()\n",
    "        x_state[:,:,1] = torch.eq(grid_tensor,-1).int()\n",
    "    else:\n",
    "        x_state[:,:,0] = torch.eq(grid_tensor,-1).int()\n",
    "        x_state[:,:,1] = torch.eq(grid_tensor,1).int()\n",
    "    \n",
    "    #print('agent', x_state[:,:,0])\n",
    "    #print('opponent',x_state[:,:,1])\n",
    "    x_state_array = x_state.numpy()\n",
    "    return x_state_array\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "games 0 buffer 1\n",
      "games 1 buffer 2\n",
      "games 2 buffer 3\n",
      "games 3 buffer 4\n",
      "games 4 buffer 5\n",
      "games 5 buffer 6\n",
      "games 6 buffer 7\n",
      "games 7 buffer 8\n",
      "games 8 buffer 9\n",
      "games 9 buffer 10\n",
      "games 10 buffer 11\n",
      "games 11 buffer 12\n",
      "games 12 buffer 13\n",
      "games 13 buffer 14\n",
      "games 14 buffer 15\n",
      "games 15 buffer 16\n",
      "games 16 buffer 17\n",
      "games 17 buffer 18\n",
      "games 18 buffer 19\n",
      "games 19 buffer 20\n",
      "games 20 buffer 21\n",
      "games 21 buffer 22\n",
      "games 22 buffer 23\n",
      "games 23 buffer 24\n",
      "games 24 buffer 25\n",
      "games 25 buffer 26\n",
      "games 26 buffer 27\n",
      "games 27 buffer 28\n",
      "games 28 buffer 29\n",
      "games 29 buffer 30\n",
      "games 30 buffer 31\n",
      "games 31 buffer 32\n",
      "games 32 buffer 33\n",
      "games 33 buffer 34\n",
      "games 34 buffer 35\n",
      "games 35 buffer 36\n",
      "games 36 buffer 37\n",
      "games 37 buffer 38\n",
      "games 38 buffer 39\n",
      "games 39 buffer 40\n",
      "games 40 buffer 41\n",
      "games 41 buffer 42\n",
      "games 42 buffer 43\n",
      "games 43 buffer 44\n",
      "games 44 buffer 45\n",
      "games 45 buffer 46\n",
      "games 46 buffer 47\n",
      "games 47 buffer 48\n",
      "games 48 buffer 49\n",
      "games 49 buffer 50\n",
      "games 50 buffer 51\n",
      "games 51 buffer 52\n",
      "games 52 buffer 53\n",
      "games 53 buffer 54\n",
      "games 54 buffer 55\n",
      "games 55 buffer 56\n",
      "games 56 buffer 57\n",
      "games 57 buffer 58\n",
      "games 58 buffer 59\n",
      "games 59 buffer 60\n",
      "games 60 buffer 61\n",
      "games 61 buffer 62\n",
      "games 62 buffer 63\n",
      "games 63 buffer 64\n",
      "games 64 buffer 65\n",
      "games 65 buffer 66\n"
     ]
    }
   ],
   "source": [
    "Turns = np.array(['X','O'])\n",
    "MIN_REPLAY_SIZE = 10000\n",
    "\n",
    "#Initialize the Replay Buffer\n",
    "replay_buffer = deque(maxlen=BUFFER_SIZE)\n",
    "\n",
    "games = 0\n",
    "episode_reward = 0.0\n",
    "\n",
    "while(len(replay_buffer) < BATCH_SIZE):\n",
    "\n",
    "    env.reset()\n",
    "    #env.render()\n",
    "    player1 = \"X\"\n",
    "    player2 = \"O\"\n",
    "    \n",
    "    if games%2 == 0:\n",
    "        player_opt = OptimalPlayer(epsilon = 1., player = player2)\n",
    "        player_rnd = OptimalPlayer(epsilon = 1., player = player1)\n",
    "        \n",
    "    if games%2 == 1:\n",
    "\n",
    "        #change the state by *-1 when optimal player is X\n",
    "        player_opt = OptimalPlayer(epsilon = 0.5, player = player1)\n",
    "        player_rnd = OptimalPlayer(epsilon = 1., player = player2)\n",
    "        grid, _, __ = env.observe()\n",
    "        comp_move = player_opt.act(grid)\n",
    "        env.step(comp_move)\n",
    "    \n",
    "\n",
    "    \n",
    "    for j in range(5):\n",
    "\n",
    "       \n",
    "        #random agent play\n",
    "        obs = env.observe()[0]\n",
    "        state = setup_state(obs,player_rnd.player)\n",
    "        move = player_rnd.act(obs)\n",
    "        grid, end, winner = env.step(move, print_grid=False)\n",
    "        action = rev_action[move]\n",
    "        #print('action', action\n",
    "        \n",
    "        \n",
    "        if not end:\n",
    "            #optimal player play\n",
    "            move = player_opt.act(grid)\n",
    "            grid, end, winner = env.step(move, print_grid=False)\n",
    "\n",
    "        \n",
    "        new_obs = env.observe()[0]\n",
    "        new_state = setup_state(new_obs,player_rnd.player)\n",
    "       \n",
    "    \n",
    "        #transition set-off\n",
    "        rew = env.reward(player=Turns[1])\n",
    "        transition = (state, action, rew, end, new_state)\n",
    "        #print('transition', transition)\n",
    "        replay_buffer.append(transition)\n",
    "           \n",
    "        print('games', games, 'buffer', len(replay_buffer))\n",
    "        games += 1\n",
    "        \n",
    "        if end:\n",
    "            #print('-------------------------------------------')\n",
    "            #print('Game end, winner is player ' + str(winner))\n",
    "            #print('Optimal player = ' +  Turns[0])\n",
    "            #print('Random player = ' +  Turns[1])\n",
    "            #env.render()\n",
    "            env.reset()\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#for _ in range(MIN_REPLAY_SIZE):\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "print(len(replay_buffer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|- - -|\n",
      "|- - -|\n",
      "|- - -|\n",
      "\n",
      "\n",
      "game 100\n",
      "episode random 2.0\n",
      "Avg random 8.727272727272727\n",
      "episode bad predi 6.0\n",
      "Avg bad predi 5.0\n",
      "episode rew -7.0\n",
      "Avg Rew -8.454545454545455\n",
      "Loss tensor(0.0052, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 200\n",
      "episode random 6.0\n",
      "Avg random 5.904761904761905\n",
      "episode bad predi 2.0\n",
      "Avg bad predi 4.190476190476191\n",
      "episode rew -6.0\n",
      "Avg Rew -6.904761904761905\n",
      "Loss tensor(0.0021, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 300\n",
      "episode random 2.0\n",
      "Avg random 4.709677419354839\n",
      "episode bad predi 7.0\n",
      "Avg bad predi 4.516129032258065\n",
      "episode rew -9.0\n",
      "Avg Rew -7.096774193548387\n",
      "Loss tensor(0.0038, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 400\n",
      "episode random 2.0\n",
      "Avg random 4.0\n",
      "episode bad predi 7.0\n",
      "Avg bad predi 4.341463414634147\n",
      "episode rew -10.0\n",
      "Avg Rew -7.7317073170731705\n",
      "Loss tensor(0.0084, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 500\n",
      "episode random 1.0\n",
      "Avg random 3.5098039215686274\n",
      "episode bad predi 1.0\n",
      "Avg bad predi 3.843137254901961\n",
      "episode rew -6.0\n",
      "Avg Rew -7.666666666666667\n",
      "Loss tensor(0.0313, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 600\n",
      "episode random 1.0\n",
      "Avg random 3.180327868852459\n",
      "episode bad predi 3.0\n",
      "Avg bad predi 4.065573770491803\n",
      "episode rew -4.0\n",
      "Avg Rew -7.639344262295082\n",
      "Loss tensor(0.0037, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 700\n",
      "episode random 2.0\n",
      "Avg random 3.0985915492957745\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 3.507042253521127\n",
      "episode rew 0.0\n",
      "Avg Rew -6.845070422535211\n",
      "Loss tensor(0.0019, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 800\n",
      "episode random 6.0\n",
      "Avg random 3.049382716049383\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 3.074074074074074\n",
      "episode rew -1.0\n",
      "Avg Rew -6.08641975308642\n",
      "Loss tensor(0.0065, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 900\n",
      "episode random 2.0\n",
      "Avg random 2.967032967032967\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 2.758241758241758\n",
      "episode rew 0.0\n",
      "Avg Rew -5.5054945054945055\n",
      "Loss tensor(0.0115, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 1000\n",
      "episode random 3.0\n",
      "Avg random 2.93\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 2.51\n",
      "episode rew 0.0\n",
      "Avg Rew -5.03\n",
      "Loss tensor(0.0026, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 1100\n",
      "episode random 1.0\n",
      "Avg random 2.27\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 1.98\n",
      "episode rew -1.0\n",
      "Avg Rew -4.21\n",
      "Loss tensor(0.0016, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 1200\n",
      "episode random 5.0\n",
      "Avg random 2.26\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 1.66\n",
      "episode rew 0.0\n",
      "Avg Rew -3.79\n",
      "Loss tensor(0.0101, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 1300\n",
      "episode random 1.0\n",
      "Avg random 2.35\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 1.16\n",
      "episode rew -1.0\n",
      "Avg Rew -3.14\n",
      "Loss tensor(0.0050, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 1400\n",
      "episode random 1.0\n",
      "Avg random 2.47\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.79\n",
      "episode rew 0.0\n",
      "Avg Rew -2.26\n",
      "Loss tensor(0.0045, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 1500\n",
      "episode random 4.0\n",
      "Avg random 2.6\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.62\n",
      "episode rew -1.0\n",
      "Avg Rew -1.58\n",
      "Loss tensor(0.0095, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 1600\n",
      "episode random 4.0\n",
      "Avg random 2.7\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.11\n",
      "episode rew -1.0\n",
      "Avg Rew -0.92\n",
      "Loss tensor(0.0079, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 1700\n",
      "episode random 3.0\n",
      "Avg random 2.73\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.11\n",
      "episode rew -1.0\n",
      "Avg Rew -0.79\n",
      "Loss tensor(0.0024, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 1800\n",
      "episode random 4.0\n",
      "Avg random 2.71\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.11\n",
      "episode rew -3.0\n",
      "Avg Rew -0.78\n",
      "Loss tensor(0.0053, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 1900\n",
      "episode random 1.0\n",
      "Avg random 2.69\n",
      "episode bad predi 1.0\n",
      "Avg bad predi 0.1\n",
      "episode rew -1.0\n",
      "Avg Rew -0.79\n",
      "Loss tensor(0.0021, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 2000\n",
      "episode random 4.0\n",
      "Avg random 2.72\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.11\n",
      "episode rew 0.0\n",
      "Avg Rew -0.8\n",
      "Loss tensor(0.0054, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 2100\n",
      "episode random 6.0\n",
      "Avg random 2.62\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.09\n",
      "episode rew -2.0\n",
      "Avg Rew -0.77\n",
      "Loss tensor(0.0038, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 2200\n",
      "episode random 3.0\n",
      "Avg random 2.55\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.08\n",
      "episode rew -1.0\n",
      "Avg Rew -0.73\n",
      "Loss tensor(0.0028, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 2300\n",
      "episode random 1.0\n",
      "Avg random 2.46\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.08\n",
      "episode rew 0.0\n",
      "Avg Rew -0.67\n",
      "Loss tensor(0.0017, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 2400\n",
      "episode random 3.0\n",
      "Avg random 2.41\n",
      "episode bad predi 1.0\n",
      "Avg bad predi 0.09\n",
      "episode rew -1.0\n",
      "Avg Rew -0.63\n",
      "Loss tensor(4.2001e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 2500\n",
      "episode random 0.0\n",
      "Avg random 2.33\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.09\n",
      "episode rew 0.0\n",
      "Avg Rew -0.61\n",
      "Loss tensor(3.3295e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 2600\n",
      "episode random 2.0\n",
      "Avg random 2.29\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.08\n",
      "episode rew -1.0\n",
      "Avg Rew -0.58\n",
      "Loss tensor(8.3722e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 2700\n",
      "episode random 3.0\n",
      "Avg random 2.31\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.07\n",
      "episode rew -1.0\n",
      "Avg Rew -0.55\n",
      "Loss tensor(0.0001, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 2800\n",
      "episode random 0.0\n",
      "Avg random 2.27\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.08\n",
      "episode rew 0.0\n",
      "Avg Rew -0.58\n",
      "Loss tensor(2.0052e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 2900\n",
      "episode random 2.0\n",
      "Avg random 2.32\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.08\n",
      "episode rew -2.0\n",
      "Avg Rew -0.6\n",
      "Loss tensor(3.7183e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 3000\n",
      "episode random 2.0\n",
      "Avg random 2.31\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.08\n",
      "episode rew 0.0\n",
      "Avg Rew -0.66\n",
      "Loss tensor(8.7255e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 3100\n",
      "episode random 1.0\n",
      "Avg random 2.35\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.08\n",
      "episode rew 0.0\n",
      "Avg Rew -0.67\n",
      "Loss tensor(0.0001, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 3200\n",
      "episode random 2.0\n",
      "Avg random 2.35\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.08\n",
      "episode rew 0.0\n",
      "Avg Rew -0.65\n",
      "Loss tensor(0.0003, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 3300\n",
      "episode random 0.0\n",
      "Avg random 2.3\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.06\n",
      "episode rew 0.0\n",
      "Avg Rew -0.64\n",
      "Loss tensor(0.0001, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 3400\n",
      "episode random 4.0\n",
      "Avg random 2.29\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.04\n",
      "episode rew -1.0\n",
      "Avg Rew -0.65\n",
      "Loss tensor(3.5642e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 3500\n",
      "episode random 7.0\n",
      "Avg random 2.35\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.03\n",
      "episode rew -2.0\n",
      "Avg Rew -0.72\n",
      "Loss tensor(6.2432e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 3600\n",
      "episode random 1.0\n",
      "Avg random 2.37\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.03\n",
      "episode rew 0.0\n",
      "Avg Rew -0.75\n",
      "Loss tensor(3.6452e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 3700\n",
      "episode random 2.0\n",
      "Avg random 2.25\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.03\n",
      "episode rew 0.0\n",
      "Avg Rew -0.75\n",
      "Loss tensor(1.8812e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 3800\n",
      "episode random 2.0\n",
      "Avg random 2.27\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.02\n",
      "episode rew 0.0\n",
      "Avg Rew -0.71\n",
      "Loss tensor(2.8938e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 3900\n",
      "episode random 1.0\n",
      "Avg random 2.28\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.02\n",
      "episode rew 0.0\n",
      "Avg Rew -0.64\n",
      "Loss tensor(0.0004, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 4000\n",
      "episode random 2.0\n",
      "Avg random 2.28\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.01\n",
      "episode rew -2.0\n",
      "Avg Rew -0.6\n",
      "Loss tensor(5.2177e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 4100\n",
      "episode random 3.0\n",
      "Avg random 2.34\n",
      "episode bad predi 1.0\n",
      "Avg bad predi 0.04\n",
      "episode rew -1.0\n",
      "Avg Rew -0.6\n",
      "Loss tensor(4.1390e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 4200\n",
      "episode random 1.0\n",
      "Avg random 2.37\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.04\n",
      "episode rew -1.0\n",
      "Avg Rew -0.61\n",
      "Loss tensor(0.0002, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 4300\n",
      "episode random 2.0\n",
      "Avg random 2.51\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.04\n",
      "episode rew 0.0\n",
      "Avg Rew -0.63\n",
      "Loss tensor(3.2093e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 4400\n",
      "episode random 3.0\n",
      "Avg random 2.58\n",
      "episode bad predi 1.0\n",
      "Avg bad predi 0.05\n",
      "episode rew -2.0\n",
      "Avg Rew -0.68\n",
      "Loss tensor(2.0347e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 4500\n",
      "episode random 1.0\n",
      "Avg random 2.52\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.05\n",
      "episode rew 0.0\n",
      "Avg Rew -0.59\n",
      "Loss tensor(3.3317e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 4600\n",
      "episode random 2.0\n",
      "Avg random 2.55\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.05\n",
      "episode rew -1.0\n",
      "Avg Rew -0.56\n",
      "Loss tensor(7.1387e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 4700\n",
      "episode random 3.0\n",
      "Avg random 2.66\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.07\n",
      "episode rew 0.0\n",
      "Avg Rew -0.58\n",
      "Loss tensor(0.0002, grad_fn=<HuberLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "game 4800\n",
      "episode random 4.0\n",
      "Avg random 2.6\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.08\n",
      "episode rew -1.0\n",
      "Avg Rew -0.59\n",
      "Loss tensor(0.0014, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 4900\n",
      "episode random 2.0\n",
      "Avg random 2.5\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.07\n",
      "episode rew 0.0\n",
      "Avg Rew -0.61\n",
      "Loss tensor(1.0949e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 5000\n",
      "episode random 0.0\n",
      "Avg random 2.48\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.1\n",
      "episode rew 0.0\n",
      "Avg Rew -0.65\n",
      "Loss tensor(1.4346e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 5100\n",
      "episode random 2.0\n",
      "Avg random 2.39\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.17\n",
      "episode rew 0.0\n",
      "Avg Rew -0.82\n",
      "Loss tensor(0.0002, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 5200\n",
      "episode random 3.0\n",
      "Avg random 2.45\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.17\n",
      "episode rew -1.0\n",
      "Avg Rew -0.82\n",
      "Loss tensor(5.0858e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 5300\n",
      "episode random 1.0\n",
      "Avg random 2.37\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.17\n",
      "episode rew 0.0\n",
      "Avg Rew -0.81\n",
      "Loss tensor(0.0003, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 5400\n",
      "episode random 0.0\n",
      "Avg random 2.28\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.21\n",
      "episode rew 0.0\n",
      "Avg Rew -0.78\n",
      "Loss tensor(4.1779e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 5500\n",
      "episode random 2.0\n",
      "Avg random 2.3\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.23\n",
      "episode rew -1.0\n",
      "Avg Rew -0.83\n",
      "Loss tensor(1.7713e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 5600\n",
      "episode random 4.0\n",
      "Avg random 2.28\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.24\n",
      "episode rew 0.0\n",
      "Avg Rew -0.85\n",
      "Loss tensor(1.4627e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 5700\n",
      "episode random 4.0\n",
      "Avg random 2.3\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.22\n",
      "episode rew -1.0\n",
      "Avg Rew -0.88\n",
      "Loss tensor(5.3866e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 5800\n",
      "episode random 2.0\n",
      "Avg random 2.46\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.21\n",
      "episode rew 0.0\n",
      "Avg Rew -0.9\n",
      "Loss tensor(2.5313e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 5900\n",
      "episode random 3.0\n",
      "Avg random 2.5\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.23\n",
      "episode rew -1.0\n",
      "Avg Rew -0.92\n",
      "Loss tensor(2.3618e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 6000\n",
      "episode random 1.0\n",
      "Avg random 2.47\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.2\n",
      "episode rew -1.0\n",
      "Avg Rew -0.91\n",
      "Loss tensor(0.0004, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 6100\n",
      "episode random 4.0\n",
      "Avg random 2.53\n",
      "episode bad predi 1.0\n",
      "Avg bad predi 0.12\n",
      "episode rew -2.0\n",
      "Avg Rew -0.73\n",
      "Loss tensor(1.6895e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 6200\n",
      "episode random 4.0\n",
      "Avg random 2.56\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.14\n",
      "episode rew 0.0\n",
      "Avg Rew -0.76\n",
      "Loss tensor(8.0604e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 6300\n",
      "episode random 3.0\n",
      "Avg random 2.61\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.21\n",
      "episode rew -1.0\n",
      "Avg Rew -0.85\n",
      "Loss tensor(8.1392e-06, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 6400\n",
      "episode random 1.0\n",
      "Avg random 2.59\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.16\n",
      "episode rew 0.0\n",
      "Avg Rew -0.84\n",
      "Loss tensor(0.0001, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 6500\n",
      "episode random 2.0\n",
      "Avg random 2.72\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.15\n",
      "episode rew -1.0\n",
      "Avg Rew -0.86\n",
      "Loss tensor(2.7372e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 6600\n",
      "episode random 2.0\n",
      "Avg random 2.69\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.14\n",
      "episode rew -1.0\n",
      "Avg Rew -0.9\n",
      "Loss tensor(3.0035e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 6700\n",
      "episode random 3.0\n",
      "Avg random 2.59\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.14\n",
      "episode rew 0.0\n",
      "Avg Rew -0.86\n",
      "Loss tensor(9.5806e-06, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 6800\n",
      "episode random 1.0\n",
      "Avg random 2.45\n",
      "episode bad predi 1.0\n",
      "Avg bad predi 0.15\n",
      "episode rew -1.0\n",
      "Avg Rew -0.83\n",
      "Loss tensor(3.3263e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 6900\n",
      "episode random 4.0\n",
      "Avg random 2.44\n",
      "episode bad predi 1.0\n",
      "Avg bad predi 0.14\n",
      "episode rew -1.0\n",
      "Avg Rew -0.82\n",
      "Loss tensor(1.2781e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 7000\n",
      "episode random 1.0\n",
      "Avg random 2.5\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.14\n",
      "episode rew -1.0\n",
      "Avg Rew -0.81\n",
      "Loss tensor(3.3572e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 7100\n",
      "episode random 3.0\n",
      "Avg random 2.43\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.12\n",
      "episode rew -1.0\n",
      "Avg Rew -0.82\n",
      "Loss tensor(7.5627e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 7200\n",
      "episode random 1.0\n",
      "Avg random 2.39\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.1\n",
      "episode rew -1.0\n",
      "Avg Rew -0.83\n",
      "Loss tensor(8.2977e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 7300\n",
      "episode random 2.0\n",
      "Avg random 2.35\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.03\n",
      "episode rew -2.0\n",
      "Avg Rew -0.78\n",
      "Loss tensor(1.0221e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 7400\n",
      "episode random 2.0\n",
      "Avg random 2.34\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.03\n",
      "episode rew 0.0\n",
      "Avg Rew -0.76\n",
      "Loss tensor(0.0007, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 7500\n",
      "episode random 3.0\n",
      "Avg random 2.22\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.02\n",
      "episode rew 0.0\n",
      "Avg Rew -0.75\n",
      "Loss tensor(1.1840e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 7600\n",
      "episode random 2.0\n",
      "Avg random 2.29\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.02\n",
      "episode rew -1.0\n",
      "Avg Rew -0.69\n",
      "Loss tensor(3.1609e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 7700\n",
      "episode random 1.0\n",
      "Avg random 2.29\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.02\n",
      "episode rew -1.0\n",
      "Avg Rew -0.71\n",
      "Loss tensor(3.6655e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 7800\n",
      "episode random 5.0\n",
      "Avg random 2.36\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.03\n",
      "episode rew -2.0\n",
      "Avg Rew -0.76\n",
      "Loss tensor(5.7062e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 7900\n",
      "episode random 2.0\n",
      "Avg random 2.41\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.03\n",
      "episode rew 0.0\n",
      "Avg Rew -0.74\n",
      "Loss tensor(0.0009, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 8000\n",
      "episode random 2.0\n",
      "Avg random 2.37\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.03\n",
      "episode rew -1.0\n",
      "Avg Rew -0.74\n",
      "Loss tensor(2.5931e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 8100\n",
      "episode random 5.0\n",
      "Avg random 2.48\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.04\n",
      "episode rew 0.0\n",
      "Avg Rew -0.69\n",
      "Loss tensor(2.0378e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 8200\n",
      "episode random 1.0\n",
      "Avg random 2.39\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.04\n",
      "episode rew 0.0\n",
      "Avg Rew -0.66\n",
      "Loss tensor(0.0005, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 8300\n",
      "episode random 3.0\n",
      "Avg random 2.45\n",
      "episode bad predi 2.0\n",
      "Avg bad predi 0.13\n",
      "episode rew -4.0\n",
      "Avg Rew -0.75\n",
      "Loss tensor(2.7935e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 8400\n",
      "episode random 2.0\n",
      "Avg random 2.45\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.15\n",
      "episode rew -1.0\n",
      "Avg Rew -0.76\n",
      "Loss tensor(1.9588e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 8500\n",
      "episode random 3.0\n",
      "Avg random 2.53\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.17\n",
      "episode rew -1.0\n",
      "Avg Rew -0.76\n",
      "Loss tensor(0.0001, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 8600\n",
      "episode random 0.0\n",
      "Avg random 2.44\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.17\n",
      "episode rew 0.0\n",
      "Avg Rew -0.74\n",
      "Loss tensor(5.3899e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 8700\n",
      "episode random 2.0\n",
      "Avg random 2.46\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.17\n",
      "episode rew -1.0\n",
      "Avg Rew -0.73\n",
      "Loss tensor(2.1292e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 8800\n",
      "episode random 4.0\n",
      "Avg random 2.43\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.15\n",
      "episode rew -1.0\n",
      "Avg Rew -0.69\n",
      "Loss tensor(3.0397e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 8900\n",
      "episode random 3.0\n",
      "Avg random 2.4\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.15\n",
      "episode rew 0.0\n",
      "Avg Rew -0.69\n",
      "Loss tensor(3.0057e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 9000\n",
      "episode random 1.0\n",
      "Avg random 2.43\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.15\n",
      "episode rew 0.0\n",
      "Avg Rew -0.69\n",
      "Loss tensor(4.2332e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 9100\n",
      "episode random 3.0\n",
      "Avg random 2.38\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.15\n",
      "episode rew -2.0\n",
      "Avg Rew -0.73\n",
      "Loss tensor(2.0017e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 9200\n",
      "episode random 1.0\n",
      "Avg random 2.47\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.15\n",
      "episode rew 0.0\n",
      "Avg Rew -0.72\n",
      "Loss tensor(4.0844e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 9300\n",
      "episode random 4.0\n",
      "Avg random 2.41\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.12\n",
      "episode rew -1.0\n",
      "Avg Rew -0.65\n",
      "Loss tensor(6.2647e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 9400\n",
      "episode random 3.0\n",
      "Avg random 2.42\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.1\n",
      "episode rew -1.0\n",
      "Avg Rew -0.64\n",
      "Loss tensor(7.3407e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 9500\n",
      "episode random 2.0\n",
      "Avg random 2.36\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.09\n",
      "episode rew 0.0\n",
      "Avg Rew -0.67\n",
      "Loss tensor(3.8773e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 9600\n",
      "episode random 0.0\n",
      "Avg random 2.42\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.09\n",
      "episode rew 0.0\n",
      "Avg Rew -0.72\n",
      "Loss tensor(7.4732e-05, grad_fn=<HuberLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "game 9700\n",
      "episode random 3.0\n",
      "Avg random 2.41\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.09\n",
      "episode rew 0.0\n",
      "Avg Rew -0.72\n",
      "Loss tensor(0.0006, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 9800\n",
      "episode random 3.0\n",
      "Avg random 2.47\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.09\n",
      "episode rew 0.0\n",
      "Avg Rew -0.71\n",
      "Loss tensor(0.0003, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 9900\n",
      "episode random 1.0\n",
      "Avg random 2.46\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.08\n",
      "episode rew 0.0\n",
      "Avg Rew -0.7\n",
      "Loss tensor(0.0003, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 10000\n",
      "episode random 4.0\n",
      "Avg random 2.4\n",
      "episode bad predi 1.0\n",
      "Avg bad predi 0.09\n",
      "episode rew -1.0\n",
      "Avg Rew -0.67\n",
      "Loss tensor(1.0544e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 10100\n",
      "episode random 3.0\n",
      "Avg random 2.46\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.08\n",
      "episode rew 0.0\n",
      "Avg Rew -0.65\n",
      "Loss tensor(1.5095e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 10200\n",
      "episode random 1.0\n",
      "Avg random 2.34\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.08\n",
      "episode rew 0.0\n",
      "Avg Rew -0.63\n",
      "Loss tensor(6.7777e-06, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 10300\n",
      "episode random 0.0\n",
      "Avg random 2.29\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.03\n",
      "episode rew 0.0\n",
      "Avg Rew -0.64\n",
      "Loss tensor(6.8664e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 10400\n",
      "episode random 3.0\n",
      "Avg random 2.31\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.03\n",
      "episode rew -1.0\n",
      "Avg Rew -0.64\n",
      "Loss tensor(0.0001, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 10500\n",
      "episode random 1.0\n",
      "Avg random 2.29\n",
      "episode bad predi 1.0\n",
      "Avg bad predi 0.09\n",
      "episode rew -1.0\n",
      "Avg Rew -0.66\n",
      "Loss tensor(2.9396e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 10600\n",
      "episode random 2.0\n",
      "Avg random 2.29\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.09\n",
      "episode rew 0.0\n",
      "Avg Rew -0.63\n",
      "Loss tensor(9.3065e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 10700\n",
      "episode random 3.0\n",
      "Avg random 2.39\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.1\n",
      "episode rew 0.0\n",
      "Avg Rew -0.67\n",
      "Loss tensor(1.1988e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 10800\n",
      "episode random 2.0\n",
      "Avg random 2.35\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.1\n",
      "episode rew -2.0\n",
      "Avg Rew -0.66\n",
      "Loss tensor(3.6916e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 10900\n",
      "episode random 4.0\n",
      "Avg random 2.35\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.1\n",
      "episode rew 0.0\n",
      "Avg Rew -0.64\n",
      "Loss tensor(3.9042e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 11000\n",
      "episode random 2.0\n",
      "Avg random 2.36\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.09\n",
      "episode rew 0.0\n",
      "Avg Rew -0.62\n",
      "Loss tensor(9.7290e-06, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 11100\n",
      "episode random 2.0\n",
      "Avg random 2.31\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.11\n",
      "episode rew -1.0\n",
      "Avg Rew -0.64\n",
      "Loss tensor(3.4726e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 11200\n",
      "episode random 4.0\n",
      "Avg random 2.51\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.12\n",
      "episode rew 0.0\n",
      "Avg Rew -0.68\n",
      "Loss tensor(3.5650e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 11300\n",
      "episode random 0.0\n",
      "Avg random 2.54\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.23\n",
      "episode rew 0.0\n",
      "Avg Rew -0.72\n",
      "Loss tensor(7.3066e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 11400\n",
      "episode random 4.0\n",
      "Avg random 2.61\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.24\n",
      "episode rew -1.0\n",
      "Avg Rew -0.74\n",
      "Loss tensor(4.9932e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 11500\n",
      "episode random 3.0\n",
      "Avg random 2.64\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.17\n",
      "episode rew 0.0\n",
      "Avg Rew -0.64\n",
      "Loss tensor(2.4005e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 11600\n",
      "episode random 2.0\n",
      "Avg random 2.59\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.18\n",
      "episode rew 0.0\n",
      "Avg Rew -0.65\n",
      "Loss tensor(1.7567e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 11700\n",
      "episode random 4.0\n",
      "Avg random 2.56\n",
      "episode bad predi 1.0\n",
      "Avg bad predi 0.18\n",
      "episode rew -2.0\n",
      "Avg Rew -0.64\n",
      "Loss tensor(1.9877e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 11800\n",
      "episode random 2.0\n",
      "Avg random 2.52\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.18\n",
      "episode rew 0.0\n",
      "Avg Rew -0.61\n",
      "Loss tensor(0.0011, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 11900\n",
      "episode random 3.0\n",
      "Avg random 2.65\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.18\n",
      "episode rew 0.0\n",
      "Avg Rew -0.67\n",
      "Loss tensor(1.5285e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 12000\n",
      "episode random 5.0\n",
      "Avg random 2.68\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.18\n",
      "episode rew -1.0\n",
      "Avg Rew -0.71\n",
      "Loss tensor(4.6824e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 12100\n",
      "episode random 7.0\n",
      "Avg random 2.73\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.18\n",
      "episode rew -2.0\n",
      "Avg Rew -0.71\n",
      "Loss tensor(2.4067e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 12200\n",
      "episode random 1.0\n",
      "Avg random 2.58\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.17\n",
      "episode rew 0.0\n",
      "Avg Rew -0.69\n",
      "Loss tensor(4.2510e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 12300\n",
      "episode random 3.0\n",
      "Avg random 2.51\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.05\n",
      "episode rew -1.0\n",
      "Avg Rew -0.59\n",
      "Loss tensor(5.0886e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 12400\n",
      "episode random 0.0\n",
      "Avg random 2.45\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.04\n",
      "episode rew 0.0\n",
      "Avg Rew -0.56\n",
      "Loss tensor(3.1732e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 12500\n",
      "episode random 3.0\n",
      "Avg random 2.4\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.1\n",
      "episode rew 0.0\n",
      "Avg Rew -0.62\n",
      "Loss tensor(7.1691e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 12600\n",
      "episode random 1.0\n",
      "Avg random 2.42\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.09\n",
      "episode rew 0.0\n",
      "Avg Rew -0.59\n",
      "Loss tensor(2.9053e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 12700\n",
      "episode random 1.0\n",
      "Avg random 2.28\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.08\n",
      "episode rew 0.0\n",
      "Avg Rew -0.57\n",
      "Loss tensor(3.6778e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 12800\n",
      "episode random 5.0\n",
      "Avg random 2.37\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.09\n",
      "episode rew -2.0\n",
      "Avg Rew -0.64\n",
      "Loss tensor(3.1390e-06, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 12900\n",
      "episode random 1.0\n",
      "Avg random 2.26\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.09\n",
      "episode rew 0.0\n",
      "Avg Rew -0.62\n",
      "Loss tensor(1.9069e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 13000\n",
      "episode random 5.0\n",
      "Avg random 2.28\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.09\n",
      "episode rew 0.0\n",
      "Avg Rew -0.63\n",
      "Loss tensor(2.9840e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 13100\n",
      "episode random 2.0\n",
      "Avg random 2.14\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.12\n",
      "episode rew 0.0\n",
      "Avg Rew -0.62\n",
      "Loss tensor(1.0992e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 13200\n",
      "episode random 2.0\n",
      "Avg random 2.09\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.16\n",
      "episode rew -2.0\n",
      "Avg Rew -0.66\n",
      "Loss tensor(0.0001, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 13300\n",
      "episode random 0.0\n",
      "Avg random 2.14\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.16\n",
      "episode rew 0.0\n",
      "Avg Rew -0.61\n",
      "Loss tensor(1.7228e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 13400\n",
      "episode random 1.0\n",
      "Avg random 2.14\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.16\n",
      "episode rew 0.0\n",
      "Avg Rew -0.65\n",
      "Loss tensor(1.4525e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 13500\n",
      "episode random 0.0\n",
      "Avg random 2.06\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.1\n",
      "episode rew 0.0\n",
      "Avg Rew -0.6\n",
      "Loss tensor(3.7790e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 13600\n",
      "episode random 2.0\n",
      "Avg random 2.05\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.13\n",
      "episode rew 0.0\n",
      "Avg Rew -0.62\n",
      "Loss tensor(3.0790e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 13700\n",
      "episode random 1.0\n",
      "Avg random 2.18\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.13\n",
      "episode rew -1.0\n",
      "Avg Rew -0.63\n",
      "Loss tensor(2.9143e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 13800\n",
      "episode random 1.0\n",
      "Avg random 2.09\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.12\n",
      "episode rew 0.0\n",
      "Avg Rew -0.59\n",
      "Loss tensor(3.4886e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 13900\n",
      "episode random 3.0\n",
      "Avg random 2.08\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.12\n",
      "episode rew 0.0\n",
      "Avg Rew -0.57\n",
      "Loss tensor(0.0001, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 14000\n",
      "episode random 3.0\n",
      "Avg random 2.13\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.12\n",
      "episode rew 0.0\n",
      "Avg Rew -0.53\n",
      "Loss tensor(3.8737e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 14100\n",
      "episode random 1.0\n",
      "Avg random 2.19\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.07\n",
      "episode rew 0.0\n",
      "Avg Rew -0.51\n",
      "Loss tensor(2.3372e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 14200\n",
      "episode random 1.0\n",
      "Avg random 2.29\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.03\n",
      "episode rew -1.0\n",
      "Avg Rew -0.51\n",
      "Loss tensor(3.6744e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 14300\n",
      "episode random 2.0\n",
      "Avg random 2.34\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.03\n",
      "episode rew 0.0\n",
      "Avg Rew -0.57\n",
      "Loss tensor(2.9696e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 14400\n",
      "episode random 3.0\n",
      "Avg random 2.48\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.04\n",
      "episode rew -2.0\n",
      "Avg Rew -0.57\n",
      "Loss tensor(3.0766e-05, grad_fn=<HuberLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "game 14500\n",
      "episode random 2.0\n",
      "Avg random 2.61\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.12\n",
      "episode rew 0.0\n",
      "Avg Rew -0.66\n",
      "Loss tensor(5.4186e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 14600\n",
      "episode random 1.0\n",
      "Avg random 2.56\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.09\n",
      "episode rew 0.0\n",
      "Avg Rew -0.66\n",
      "Loss tensor(6.2423e-06, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 14700\n",
      "episode random 1.0\n",
      "Avg random 2.53\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.09\n",
      "episode rew 0.0\n",
      "Avg Rew -0.62\n",
      "Loss tensor(3.1732e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 14800\n",
      "episode random 2.0\n",
      "Avg random 2.57\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.09\n",
      "episode rew 0.0\n",
      "Avg Rew -0.62\n",
      "Loss tensor(1.1998e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 14900\n",
      "episode random 3.0\n",
      "Avg random 2.68\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.09\n",
      "episode rew -1.0\n",
      "Avg Rew -0.65\n",
      "Loss tensor(2.5686e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 15000\n",
      "episode random 6.0\n",
      "Avg random 2.66\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.09\n",
      "episode rew -1.0\n",
      "Avg Rew -0.65\n",
      "Loss tensor(5.8567e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 15100\n",
      "episode random 1.0\n",
      "Avg random 2.72\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.09\n",
      "episode rew 0.0\n",
      "Avg Rew -0.66\n",
      "Loss tensor(4.1177e-06, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 15200\n",
      "episode random 1.0\n",
      "Avg random 2.75\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.09\n",
      "episode rew 0.0\n",
      "Avg Rew -0.62\n",
      "Loss tensor(1.8909e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 15300\n",
      "episode random 4.0\n",
      "Avg random 2.75\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.09\n",
      "episode rew -1.0\n",
      "Avg Rew -0.63\n",
      "Loss tensor(4.4524e-06, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 15400\n",
      "episode random 4.0\n",
      "Avg random 2.62\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.08\n",
      "episode rew -1.0\n",
      "Avg Rew -0.65\n",
      "Loss tensor(1.1426e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 15500\n",
      "episode random 3.0\n",
      "Avg random 2.66\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.0\n",
      "episode rew -2.0\n",
      "Avg Rew -0.62\n",
      "Loss tensor(7.5468e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 15600\n",
      "episode random 3.0\n",
      "Avg random 2.82\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.0\n",
      "episode rew 0.0\n",
      "Avg Rew -0.59\n",
      "Loss tensor(8.6939e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 15700\n",
      "episode random 4.0\n",
      "Avg random 2.91\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.0\n",
      "episode rew -1.0\n",
      "Avg Rew -0.61\n",
      "Loss tensor(3.3466e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 15800\n",
      "episode random 5.0\n",
      "Avg random 3.0\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.02\n",
      "episode rew 0.0\n",
      "Avg Rew -0.63\n",
      "Loss tensor(8.3078e-06, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 15900\n",
      "episode random 4.0\n",
      "Avg random 2.89\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.09\n",
      "episode rew -1.0\n",
      "Avg Rew -0.67\n",
      "Loss tensor(1.7334e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 16000\n",
      "episode random 0.0\n",
      "Avg random 2.88\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.09\n",
      "episode rew 0.0\n",
      "Avg Rew -0.75\n",
      "Loss tensor(1.1332e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 16100\n",
      "episode random 4.0\n",
      "Avg random 2.9\n",
      "episode bad predi 1.0\n",
      "Avg bad predi 0.1\n",
      "episode rew -2.0\n",
      "Avg Rew -0.75\n",
      "Loss tensor(1.4286e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 16200\n",
      "episode random 2.0\n",
      "Avg random 2.92\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.1\n",
      "episode rew -1.0\n",
      "Avg Rew -0.74\n",
      "Loss tensor(6.7190e-06, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 16300\n",
      "episode random 0.0\n",
      "Avg random 2.93\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.1\n",
      "episode rew 0.0\n",
      "Avg Rew -0.72\n",
      "Loss tensor(1.9236e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 16400\n",
      "episode random 2.0\n",
      "Avg random 2.9\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.1\n",
      "episode rew 0.0\n",
      "Avg Rew -0.68\n",
      "Loss tensor(2.5808e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 16500\n",
      "episode random 1.0\n",
      "Avg random 2.89\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.1\n",
      "episode rew 0.0\n",
      "Avg Rew -0.65\n",
      "Loss tensor(6.2451e-06, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 16600\n",
      "episode random 3.0\n",
      "Avg random 2.84\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.1\n",
      "episode rew -1.0\n",
      "Avg Rew -0.66\n",
      "Loss tensor(2.5065e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 16700\n",
      "episode random 1.0\n",
      "Avg random 2.71\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.11\n",
      "episode rew 0.0\n",
      "Avg Rew -0.66\n",
      "Loss tensor(1.4172e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 16800\n",
      "episode random 0.0\n",
      "Avg random 2.68\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.09\n",
      "episode rew 0.0\n",
      "Avg Rew -0.62\n",
      "Loss tensor(1.7165e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 16900\n",
      "episode random 1.0\n",
      "Avg random 2.82\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.02\n",
      "episode rew -1.0\n",
      "Avg Rew -0.61\n",
      "Loss tensor(7.1207e-06, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 17000\n",
      "episode random 2.0\n",
      "Avg random 2.91\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.02\n",
      "episode rew -2.0\n",
      "Avg Rew -0.65\n",
      "Loss tensor(2.9627e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 17100\n",
      "episode random 4.0\n",
      "Avg random 2.81\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.01\n",
      "episode rew -2.0\n",
      "Avg Rew -0.66\n",
      "Loss tensor(0.0002, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 17200\n",
      "episode random 3.0\n",
      "Avg random 2.76\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.01\n",
      "episode rew -2.0\n",
      "Avg Rew -0.72\n",
      "Loss tensor(2.2863e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 17300\n",
      "episode random 0.0\n",
      "Avg random 2.72\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.02\n",
      "episode rew 0.0\n",
      "Avg Rew -0.74\n",
      "Loss tensor(2.6318e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 17400\n",
      "episode random 2.0\n",
      "Avg random 2.82\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.02\n",
      "episode rew 0.0\n",
      "Avg Rew -0.73\n",
      "Loss tensor(1.0567e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 17500\n",
      "episode random 4.0\n",
      "Avg random 2.76\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.02\n",
      "episode rew -1.0\n",
      "Avg Rew -0.72\n",
      "Loss tensor(3.6364e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 17600\n",
      "episode random 2.0\n",
      "Avg random 2.76\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.02\n",
      "episode rew 0.0\n",
      "Avg Rew -0.75\n",
      "Loss tensor(2.3373e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 17700\n",
      "episode random 2.0\n",
      "Avg random 2.74\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.01\n",
      "episode rew 0.0\n",
      "Avg Rew -0.74\n",
      "Loss tensor(1.2421e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 17800\n",
      "episode random 5.0\n",
      "Avg random 2.7\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.01\n",
      "episode rew -1.0\n",
      "Avg Rew -0.75\n",
      "Loss tensor(3.8676e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 17900\n",
      "episode random 2.0\n",
      "Avg random 2.53\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.01\n",
      "episode rew -1.0\n",
      "Avg Rew -0.68\n",
      "Loss tensor(5.4761e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 18000\n",
      "episode random 1.0\n",
      "Avg random 2.33\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.02\n",
      "episode rew 0.0\n",
      "Avg Rew -0.57\n",
      "Loss tensor(1.1708e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 18100\n",
      "episode random 2.0\n",
      "Avg random 2.39\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.02\n",
      "episode rew -1.0\n",
      "Avg Rew -0.59\n",
      "Loss tensor(1.2419e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 18200\n",
      "episode random 4.0\n",
      "Avg random 2.35\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.03\n",
      "episode rew -1.0\n",
      "Avg Rew -0.56\n",
      "Loss tensor(1.2455e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 18300\n",
      "episode random 1.0\n",
      "Avg random 2.32\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.02\n",
      "episode rew 0.0\n",
      "Avg Rew -0.52\n",
      "Loss tensor(1.8351e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 18400\n",
      "episode random 5.0\n",
      "Avg random 2.3\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.02\n",
      "episode rew -1.0\n",
      "Avg Rew -0.52\n",
      "Loss tensor(1.4322e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 18500\n",
      "episode random 2.0\n",
      "Avg random 2.24\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.02\n",
      "episode rew 0.0\n",
      "Avg Rew -0.54\n",
      "Loss tensor(4.5212e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 18600\n",
      "episode random 4.0\n",
      "Avg random 2.18\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.02\n",
      "episode rew -1.0\n",
      "Avg Rew -0.53\n",
      "Loss tensor(1.2460e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 18700\n",
      "episode random 3.0\n",
      "Avg random 2.27\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.04\n",
      "episode rew -1.0\n",
      "Avg Rew -0.52\n",
      "Loss tensor(3.3901e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 18800\n",
      "episode random 3.0\n",
      "Avg random 2.31\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.04\n",
      "episode rew 0.0\n",
      "Avg Rew -0.54\n",
      "Loss tensor(1.5125e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 18900\n",
      "episode random 0.0\n",
      "Avg random 2.39\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.04\n",
      "episode rew 0.0\n",
      "Avg Rew -0.58\n",
      "Loss tensor(4.0971e-06, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 19000\n",
      "episode random 2.0\n",
      "Avg random 2.49\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.03\n",
      "episode rew 0.0\n",
      "Avg Rew -0.59\n",
      "Loss tensor(7.7966e-06, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 19100\n",
      "episode random 6.0\n",
      "Avg random 2.57\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.04\n",
      "episode rew 0.0\n",
      "Avg Rew -0.57\n",
      "Loss tensor(5.0361e-06, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 19200\n",
      "episode random 1.0\n",
      "Avg random 2.56\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.03\n",
      "episode rew -1.0\n",
      "Avg Rew -0.56\n",
      "Loss tensor(1.2192e-05, grad_fn=<HuberLossBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "game 19300\n",
      "episode random 3.0\n",
      "Avg random 2.55\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.03\n",
      "episode rew -1.0\n",
      "Avg Rew -0.55\n",
      "Loss tensor(4.5577e-06, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 19400\n",
      "episode random 2.0\n",
      "Avg random 2.46\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.04\n",
      "episode rew -1.0\n",
      "Avg Rew -0.54\n",
      "Loss tensor(3.2647e-06, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 19500\n",
      "episode random 3.0\n",
      "Avg random 2.49\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.04\n",
      "episode rew -1.0\n",
      "Avg Rew -0.48\n",
      "Loss tensor(6.0110e-06, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 19600\n",
      "episode random 2.0\n",
      "Avg random 2.52\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.05\n",
      "episode rew -1.0\n",
      "Avg Rew -0.47\n",
      "Loss tensor(2.8232e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 19700\n",
      "episode random 3.0\n",
      "Avg random 2.59\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.03\n",
      "episode rew 0.0\n",
      "Avg Rew -0.52\n",
      "Loss tensor(8.0276e-06, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 19800\n",
      "episode random 2.0\n",
      "Avg random 2.55\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.03\n",
      "episode rew -1.0\n",
      "Avg Rew -0.53\n",
      "Loss tensor(6.3772e-06, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 19900\n",
      "episode random 2.0\n",
      "Avg random 2.43\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.03\n",
      "episode rew 0.0\n",
      "Avg Rew -0.49\n",
      "Loss tensor(1.9523e-05, grad_fn=<HuberLossBackward0>)\n",
      "\n",
      "game 20000\n",
      "episode random 4.0\n",
      "Avg random 2.41\n",
      "episode bad predi 0.0\n",
      "Avg bad predi 0.03\n",
      "episode rew 0.0\n",
      "Avg Rew -0.48\n",
      "Loss tensor(9.0797e-06, grad_fn=<HuberLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#Main Training Loop\n",
    "M_val = []\n",
    "\n",
    "Nwin = 0\n",
    "Nlos = 0\n",
    "\n",
    "player1 = \"X\"\n",
    "player2 = \"O\"\n",
    "\n",
    "env.reset()\n",
    "env.render()\n",
    "player_opt = OptimalPlayer(epsilon=0, player='O')\n",
    "\n",
    "\n",
    "optimizer = torch.optim.Adam(policy_net.parameters(), lr=5e-4)\n",
    "rew_buffer = deque([0.0], maxlen=100)\n",
    "reward_memory =[]\n",
    "bad_pred_buffer = deque([0.0], maxlen=100)\n",
    "random_buffer = deque([0.0], maxlen=100)\n",
    "\n",
    "loss_buffer = deque([0.0], maxlen=100)\n",
    "\n",
    "game = 0\n",
    "old_game = 0\n",
    "step = 0\n",
    "bad_prediction = False\n",
    "\n",
    "episode_reward = 0.0\n",
    "episode_bad_predict = 0.0\n",
    "episode_random = 0.0\n",
    "\n",
    "criterion = torch.nn.HuberLoss(delta=1.0)\n",
    "\n",
    "new_game = True\n",
    "while(game < 20000):\n",
    "    step +=1\n",
    "    epsilon = np.interp(step, [0, EPS_DECAY], [EPS_START,EPS_END])\n",
    "    \n",
    "    \n",
    "    if new_game:\n",
    "        new_game = False\n",
    "        if games%2 == 0:\n",
    "            player_opt = OptimalPlayer(epsilon = 0, player = player2)\n",
    "            agent_tag =  player1\n",
    "        \n",
    "        if games%2 == 1:\n",
    "            #change the state by *-1 when optimal player is X\n",
    "            player_opt = OptimalPlayer(epsilon = 0, player = player1)\n",
    "            agent_tag = player2\n",
    "            grid, _, __ = env.observe()\n",
    "            comp_move = player_opt.act(grid)\n",
    "            env.step(comp_move)\n",
    "        \n",
    "    \n",
    "   \n",
    "    #random agent play\n",
    "    rnd_sample = random.random()\n",
    "    obs = env.observe()[0]\n",
    "    state = setup_state(obs,agent_tag)\n",
    "    available_action = find_aval_actions(obs, list_of_action)\n",
    "    if rnd_sample <= epsilon:\n",
    "        random_int = random.randint(0,len(available_action)-1)\n",
    "        #print('random_int', random_int, 'len available action',len(available_action))\n",
    "        move = available_action[random_int]\n",
    "        #print('move',move)\n",
    "        episode_random +=1\n",
    "    else:\n",
    "        move = policy_net.act(state)\n",
    "        #print('move',move)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if not move in available_action:\n",
    "        #print(' bad prediction', available_action)\n",
    "        bad_prediction = True\n",
    "        \n",
    "    \n",
    "    \n",
    "    if not bad_prediction:\n",
    "        #print('env step')\n",
    "        grid, end, winner = env.step(move, print_grid=False)\n",
    "        #env.render()\n",
    "        \n",
    "    action = move\n",
    "    #print('###### action #####',action)\n",
    "    #env.render()\n",
    "    \n",
    "    if (not end) and (not bad_prediction):\n",
    "        #optimal player play\n",
    "        move = player_opt.act(grid)\n",
    "        #print('optimal move', move)\n",
    "        \n",
    "        grid, end, winner = env.step(move, print_grid=False)\n",
    "        #env.render()\n",
    "    \n",
    "\n",
    "    #transition set-off\n",
    "    new_obs = env.observe()[0]\n",
    "    new_state = setup_state(new_obs,agent_tag)\n",
    "    if not bad_prediction:\n",
    "        rew = env.reward(player='X')\n",
    "        transition = (state, action, rew, end, new_state)\n",
    "    else:\n",
    "        rew = -1\n",
    "        transition = (state, action, rew, True, new_state)\n",
    "        #end = False\n",
    "    \n",
    "    #print('transition', transition)\n",
    "    replay_buffer.append(transition)\n",
    "    \n",
    "    \n",
    "    if end or bad_prediction:\n",
    "        new_game = True\n",
    "        #print('game finish')\n",
    "        if bad_prediction:\n",
    "            episode_bad_predict += 1\n",
    "            Nlos += 1 \n",
    "        \n",
    "        if rew == 1:\n",
    "            Nwin += 1\n",
    "            \n",
    "        if game % 500 == 0:\n",
    "            M_val.append((Nwin-Nlos)/500)\n",
    "            Nwin = 0\n",
    "            Nlos = 0\n",
    "            \n",
    "            \n",
    "        bad_prediction = False\n",
    "        #print('-------------------------------------------')\n",
    "        #print('Game end, winner is player ' + str(winner))\n",
    "        #print('Optimal player = ' +  Turns[0])\n",
    "        #print('Random player = ' +  Turns[1])\n",
    "        #env.render()\n",
    "        env.reset()\n",
    "        episode_reward += rew\n",
    "        game += 1\n",
    "        if game % 10 == 0:\n",
    "            \n",
    "            loss_buffer.append(loss.detach().numpy())\n",
    "            rew_buffer.append(episode_reward)\n",
    "            bad_pred_buffer.append(episode_bad_predict)\n",
    "            random_buffer.append(episode_random)\n",
    "\n",
    "            # Logging\n",
    "            if game % 100 == 0:\n",
    "                reward_memory.append(np.mean(rew_buffer))\n",
    "                print()\n",
    "                print('game', game)\n",
    "                print('episode random',episode_random)\n",
    "                print('Avg random', np.mean(random_buffer))\n",
    "                print('episode bad predi',episode_bad_predict)\n",
    "                print('Avg bad predi', np.mean(bad_pred_buffer))\n",
    "                print('episode rew',episode_reward)\n",
    "                print('Avg Rew', np.mean(rew_buffer)) \n",
    "                print('Loss', loss)\n",
    "            episode_reward = 0.0\n",
    "            episode_bad_predict = 0.0\n",
    "            episode_random = 0.0\n",
    "    \n",
    "    \n",
    "    # Start Gradient Step\n",
    "    #print('replay_buffer', len(replay_buffer))\n",
    "    transitions = random.sample(replay_buffer, BATCH_SIZE)\n",
    "    \n",
    "    obses = np.asarray([t[0] for t in transitions])\n",
    "    #print('obses', type(obses))\n",
    "    #print(obses)\n",
    "    actions = np.asarray([t[1] for t in transitions])\n",
    "    #print('actions type', type(actions))\n",
    "    #print(actions)\n",
    "    rews = np.asarray([t[2] for t in transitions])\n",
    "    dones = np.asarray([t[3] for t in transitions])\n",
    "    new_obses = np.asarray([t[4] for t in transitions])\n",
    "    \n",
    "    obses_tensor = torch.as_tensor(obses, dtype=torch.float32)\n",
    "    actions_tensor = torch.as_tensor(actions, dtype=torch.int64).unsqueeze(-1)\n",
    "    rews_tensor = torch.as_tensor(rews, dtype=torch.float32).unsqueeze(-1)\n",
    "    dones_tensor = torch.as_tensor(dones, dtype=torch.float32).unsqueeze(-1)\n",
    "    new_obses_tensor = torch.as_tensor(new_obses, dtype=torch.float32)\n",
    "    \n",
    "    #print('obses_tensor', obses_tensor.shape)\n",
    "    #print('new_obses_tensor', new_obses_tensor.shape)\n",
    "    \n",
    "    # Compute Targets\n",
    "    target_q_values = target_net(new_obses_tensor)\n",
    "    #print('target_q_values',target_q_values.shape)\n",
    "    #mask_possible_action = torch.ne(new_obses_tensor,0)*-1\n",
    "    #print('mask_possible_action',mask_possible_action.shape)\n",
    "    #possible_target_q_values = target_q_values * mask_possible_action\n",
    "    #print('possible_target_q_values',possible_target_q_values.shape)\n",
    "    max_target_q_values = target_q_values.max(dim=1, keepdim=True)[0]\n",
    "    #print('max_target_q_values', max_target_q_values.shape)\n",
    "    \n",
    "    targets = rews_tensor + GAMMA * ( 1 - dones_tensor)  * max_target_q_values\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Compute Loss\n",
    "    \n",
    "    q_values = policy_net(obses_tensor)\n",
    "    \n",
    "    \n",
    "    # give the q values of the action we took\n",
    "    action_q_values = torch.gather(input=q_values, dim=1, index=actions_tensor)\n",
    "    \n",
    "#     print('action_q_values',action_q_values.shape, 'targets',targets.shape)\n",
    "#     print('actions_tensor', actions_tensor[0], actions_tensor[1])\n",
    "#     print('q_values', q_values[0])\n",
    "#     print('q_values row 1', q_values[1])\n",
    "#     print('action_q_values',action_q_values[0])\n",
    "    \n",
    "    #loss = nn.functional.smooth_l1_loss(q_values_max, targets)\n",
    "    loss = criterion(action_q_values, targets)\n",
    "   \n",
    "    \n",
    "    #print('loss', loss, loss.shape, type(loss))\n",
    "#     max_q_idx = torch.argmax(possible_q_values, dim=1)[0]\n",
    "#     max_q_idx_item = max_q_idx.detach().item()\n",
    "    \n",
    "    \n",
    "    # Gradient Descent\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    # Update Target Network\n",
    "    if step % TARGET_UPDATE_FREQ == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "        \n",
    "    # Logging\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_rand = []\n",
    "M_rand = M_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(M_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_opt = []\n",
    "M_opt = M_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(M_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(M_rand, color='b', label='M_rand')\n",
    "plt.ylabel('M_rand')\n",
    "plt.xlabel('games')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(M_opt[1:], color='r', label='M_opt')\n",
    "plt.ylabel('M_opt')\n",
    "plt.xlabel('games')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEGCAYAAACtqQjWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAxx0lEQVR4nO3dd3xU1dr3/8+VRpHQQ0eKRpQmImC90VsUEUWwoKCicHNEzyN6HxuWo8fYjigqlgfw8FN8UJGiIiCCoHiUIkivQqiCoaUgEAgpk7l+f8yenCQkYYBMZs9wvV8vXjOz9157rxWS+c5aa8/eoqoYY4wx5SEq1BUwxhgTOSxUjDHGlBsLFWOMMeXGQsUYY0y5sVAxxhhTbmJCXYFQqlu3rjZv3jzU1TDGmLCyYsWKdFVNKGndGR0qzZs3Z/ny5aGuhjHGhBUR2VnaOhv+MsYYU24sVIwxxpQbCxVjjDHl5oyeUzHGmPKQl5dHSkoK2dnZoa5KuapcuTJNmjQhNjY24DIWKsYYc5pSUlKIj4+nefPmiEioq1MuVJWMjAxSUlJo0aJFwOVs+MsYY05TdnY2derUiZhAARAR6tSpc9K9LwsVY4wpB5EUKH6n0iYLFWNMWFuzbw1LUpaEuhrGYaFijAlrz//7eR6Z/UioqxFy1apVC3UVAAsVY0yYy/Zkk5OfE+pqGIeFijEmrHm8HjxeT6ir4RqqypNPPknbtm1p164dkydPBmDv3r107dqVDh060LZtWxYsWEB+fj4DBw4s2HbkyJGnfXw7pdgYE9bcFip/++5vrN63ulz32aFBB97p8U5A206dOpXVq1ezZs0a0tPT6dy5M127duXzzz/n+uuv5+9//zv5+flkZWWxevVqdu/ezfr16wE4ePDgadfVeirGmLDmtlAJtYULF9K/f3+io6OpX78+V111FcuWLaNz5858/PHHJCUlsW7dOuLj42nZsiXbt2/n4Ycf5rvvvqN69eqnfXzrqRhjwprbQiXQHkWwqGqJy7t27cr8+fP59ttvGTBgAE8++ST33nsva9asYc6cOYwaNYopU6Ywbty40zq+9VSMMWHNbaESal27dmXy5Mnk5+eTlpbG/Pnz6dKlCzt37qRevXrcf//9DB48mJUrV5Keno7X6+W2227j5ZdfZuXKlad9fOupGGPCmoVKUbfccguLFy/mwgsvRER44403aNCgAePHj2fEiBHExsZSrVo1PvnkE3bv3s2gQYPwer0AvPbaa6d9fCmtq3Qm6NSpk9pNuowJb61HtWb/0f1kDMsIWR02btzIBRdcELLjB1NJbRORFaraqaTtbfjLGBPWrKfiLhYqxpiwZqHiLhYqxpiw5pZQicSphFNpk4WKMSasuSFUKleuTEZGRkQFi/9+KpUrVz6pcnb2lzEmrHm8HrzqxateoiQ0n5ObNGlCSkoKaWlpITl+sPjv/HgyghoqItIDeBeIBj5U1eHF1ouzvieQBQxU1ZVllRWRvkAScAHQRVWXF9rfM8BgIB94RFXnBLN9xpjQ8/dS8r35REWHJlRiY2NP6u6IkSxo/wMiEg2MAm4AWgP9RaR1sc1uABKdf0OAMQGUXQ/cCswvdrzWQD+gDdADGO3sxxgTwfyhEuohMOMTzFjvAmxV1e2qmgtMAnoX26Y38In6LAFqikjDssqq6kZVTS7heL2BSaqao6o7gK3OfowxEcxCxV2CGSqNgT8KvU5xlgWyTSBlT+V4iMgQEVkuIssjbfzTmDORhYq7BDNUSrq5cfFTI0rbJpCyp3I8VHWsqnZS1U4JCQkn2KUxxu0sVNwlmBP1KUDTQq+bAHsC3CYugLKncjxjTATxqhd1PjtaqLhDMHsqy4BEEWkhInH4JtFnFNtmBnCv+FwKHFLVvQGWLW4G0E9EKolIC3yT/0vLs0HGGHcpHCQWKu4QtJ6KqnpEZCgwB99pweNUdYOIPOis/wCYhe904q34TikeVFZZABG5BXgfSAC+FZHVqnq9s+8pwG+AB3hIVfOD1T5jTOhZqLiPXaXYrlJsTNg6nHOYGsNrALB56GYS6ySGuEZnBrtKsTEmIllPxX0sVIwxYctCxX0sVIwxYctCxX0sVIwxYctCxX0sVIwxYctCxX0sVIwxYctCxX0sVIwxYctCxX0sVIwxYctCxX0sVIwxYctCxX0sVIwxYctCxX0sVIwxYctCxX0sVIwxYctCxX0sVIwxYctCxX0sVIwxYctCxX0sVIwxYctCxX0sVIwxYctCxX0sVIwxYctCxX0sVIwxYctCxX0sVIwxYctCxX0sVIwxYctCxX0sVIwxYctCxX0sVIwxYctCxX0sVIwxYctCxX0sVIwxYctCxX0sVIwxYctCxX0sVIwxYcsfJFESZaHiEhYqxpiw5Q+SyjGVLVRcIqihIiI9RCRZRLaKyNMlrBcRec9Zv1ZEOp6orIjUFpHvRWSL81jLWR4rIuNFZJ2IbBSRZ4LZNmNM6FmouE/QQkVEooFRwA1Aa6C/iLQuttkNQKLzbwgwJoCyTwPzVDURmOe8BugLVFLVdsDFwAMi0jw4rTPGuIHH60EQ4qLjLFRcIpg9lS7AVlXdrqq5wCSgd7FtegOfqM8SoKaINDxB2d7AeOf5eKCP81yBs0QkBqgC5AKHg9M0Y4wbeLweYqJiiImKsVBxiWCGSmPgj0KvU5xlgWxTVtn6qroXwHms5yz/EjgK7AV2AW+q6oHilRKRISKyXESWp6WlnUq7jDEuUSRU1ELFDYIZKlLCMg1wm0DKFtcFyAcaAS2Ax0Wk5XE7UR2rqp1UtVNCQsIJdmmMcTPrqbhPMEMlBWha6HUTYE+A25RVdr8zRIbzmOosvwv4TlXzVDUVWAR0Kod2GGNcykLFfYIZKsuARBFpISJxQD9gRrFtZgD3OmeBXQoccoa0yio7A7jPeX4fMN15vgu4xtnXWcClwKZgNc4YE3oWKu4TE6wdq6pHRIYCc4BoYJyqbhCRB531HwCzgJ7AViALGFRWWWfXw4EpIjIYX5D0dZaPAj4G1uMbPvtYVdcGq33GmNCzUHGfoIUKgKrOwhcchZd9UOi5Ag8FWtZZngF0K2H5Ef4TMMaYM4CFivvYN+qNMWHLQsV9LFSMMWHLQsV9LFSMMWHLQsV9LFSMMWHLQsV9LFSMMWHLQsV9LFSMMWHLQsV9LFSMMWHLQsV9LFSMMWHLQsV9LFSMMWHLQsV9LFSMMWGrcKjk5eeFujoGCxVjTBiznor7WKgYY8JWQaiIhYpbWKgYY8KW9VTcx0LFGBO2LFTcx0LFGBO2LFTcx0LFGBO2LFTcx0LFGBO2LFTcx0LFGBO2LFTcx0LFGBO2CoeKonjVG+oqnfEsVIwxYcsfKrHRsQWvTWhZqBhjwlbhnor/tQktCxVjTNiyUHEfCxVjTNiyUHEfCxVjTNiyUHEfCxVjTFjyqhdFLVRcxkLFGBOW/AFioeIuFirGmLBkoeJOQQ0VEekhIskislVEni5hvYjIe876tSLS8URlRaS2iHwvIlucx1qF1rUXkcUiskFE1olI5WC2zxgTOhYq7hS0UBGRaGAUcAPQGugvIq2LbXYDkOj8GwKMCaDs08A8VU0E5jmvEZEY4DPgQVVtA1wN2P1FjYlQFiruFMyeShdgq6puV9VcYBLQu9g2vYFP1GcJUFNEGp6gbG9gvPN8PNDHed4dWKuqawBUNUNV84PUNmNMiPkDJDYq1kLFRYIZKo2BPwq9TnGWBbJNWWXrq+peAOexnrP8PEBFZI6IrBSRYSVVSkSGiMhyEVmelpZ2Cs0yxriB9VTcKZihIiUs0wC3CaRscTHAlcDdzuMtItLtuJ2ojlXVTqraKSEh4QS7NMa4lYWKOwUzVFKApoVeNwH2BLhNWWX3O0NkOI+phfb1s6qmq2oWMAvoiDEmIlmouFMwQ2UZkCgiLUQkDugHzCi2zQzgXucssEuBQ86QVlllZwD3Oc/vA6Y7z+cA7UWkqjNpfxXwW7AaZ4wJLQsVdwooVETkf0WkuvPm/5EzZ9G9rDKq6gGG4nuz3whMUdUNIvKgiDzobDYL2A5sBf4/4P+UVdYpMxy4TkS2ANc5r1HVP4G38QXSamClqn4bSPuMMeHHQsWdYgLc7n9U9V0RuR5IAAYBHwNzyyqkqrPwBUfhZR8Ueq7AQ4GWdZZnAMfNlTjrPsN3WrExJsJZqLhToMNf/onznsDHzmm7JU2mG2NMhbBQcadAQ2WFiMzFFypzRCQesPt2GmNCxkLFnQId/hoMdAC2q2qWiNTGNwRmjDEhkZfvu2CGhYq7BNpTuQxIVtWDInIP8BxwKHjVMsaYsllPxZ0CDZUxQJaIXAgMA3YCnwStVsYYcwIWKu4UaKh4nDO1egPvquq7QHzwqmWMMWWzUHGnQOdUMkXkGWAA8F/OVYRjg1ctY4wpm4WKOwXaU7kTyMH3fZV9+C7uOCJotTLGmBOwUHGngELFCZIJQA0RuQnIVlWbUzHGhIyFijsFepmWO4ClQF/gDuBXEbk9mBUzxpiyWKi4U6BzKn8HOqtqKoCIJAA/AF8Gq2LGGFMWCxV3CnROJcofKI6MkyhrjDHlzkLFnQLtqXwnInOAic7rOynhYo/GGFNRLFTcKaBQUdUnReQ24Ap8F5Icq6pfB7VmxhhTBgsVdwq0p4KqfgV8FcS6GGNMwAqHSpREIYiFiguUGSoikknJ94YXfLdDqR6UWhljzAkUDhX/o4VK6JUZKqpql2IxxriShYo72RlcxpiwZKHiThYqxpiwZKHiThYqxpiw5A+Q6KhowELFLSxUjDFhyeP1ECVRRInvbcxCxR0sVIwxYcnj9RQMfYGFiltYqBhjwpKFijtZqBhjwpKFijtZqBhjwpKFijtZqBhjwpKFijtZqBhjwpKFijtZqBhjwpJHLVTcKKihIiI9RCRZRLaKyNMlrBcRec9Zv1ZEOp6orIjUFpHvRWSL81ir2D7PFpEjIvJEMNtmjAkt66m4U9BCRUSigVHADUBroL+ItC622Q1AovNvCDAmgLJPA/NUNRGY57wubCQwu9wbZIxxFQsVdwpmT6ULsFVVt6tqLjAJ6F1sm97AJ+qzBKgpIg1PULY3MN55Ph7o49+ZiPQBtgMbgtMkY4xbWKi4UzBDpTHwR6HXKc6yQLYpq2x9Vd0L4DzWAxCRs4CngBfLqpSIDBGR5SKyPC0t7aQaZIxxDwsVdwpmqEgJy4rf8Ku0bQIpW9yLwEhVPVLWRqo6VlU7qWqnhISEE+zSGONWFiruFPDthE9BCtC00OsmwJ4At4kro+x+EWmoqnudobJUZ/klwO0i8gZQE/CKSLaq/t/yaIwxxl0sVNwpmD2VZUCiiLQQkTigHzCj2DYzgHuds8AuBQ45Q1pllZ0B3Oc8vw+YDqCq/6WqzVW1OfAO8E8LFGMil4WKOwWtp6KqHhEZCswBooFxqrpBRB501n8AzAJ6AluBLGBQWWWdXQ8HpojIYGAX0DdYbTDGuJeFijsFc/gLVZ2FLzgKL/ug0HMFHgq0rLM8A+h2guMmnUJ1jTFhxOP1EBcdV/DaQsUd7Bv1xpiwZD0Vd7JQMcaEJQsVd7JQMcaEJQsVd7JQMcaEJQsVd7JQMcaEJQsVd7JQMcaEpUgNldlbZtNmdBtyPDmhrsopsVAxxoSlSA2VlXtX8lvab2Qcywh1VU6JhYoxJix5vB5iJPJC5XDO4SKP4cZCxRgTliK1p5KZm+l7zMkMcU1OjYWKMSYslRQqiuJVbwhrdfqsp2KMMSFQUqj4l4ezgp5KrvVUjDGmwpQWKnn5eaGqUrnwD3tZT8UYYypQpPZU/GFicyrGGFOBIjVUbPjLGGMqmKpGbKjYRL0xxlQw/xlekRgq/mEvG/4yxpgK4g+OSAuVfG8+R/OOAnA413oqxhhTISI1VI7kHil4bj0VY4ypIJEaKoUn522i3hhjKkjEhkqh3olN1BtjTAUpKVRio2KLrAtH/iCpGlvVhr+MMaaiRGxPxRnyahzf2HoqxhhTUSI1VPxB0ii+kc2pGGNMRYnUUPEPeTWu3pjMnExUNcQ1OnkWKsaYsBOxoVJo+EvRgu+shBMLFWNM2InUUPEPfzWObwyE53dVLFSMMWEnUkMlMyeT2KhY6latC4TnacVBDRUR6SEiySKyVUSeLmG9iMh7zvq1ItLxRGVFpLaIfC8iW5zHWs7y60RkhYiscx6vCWbbjDGhE7GhkptJfKV4qleqXvA63AQtVEQkGhgF3AC0BvqLSOtim90AJDr/hgBjAij7NDBPVROBec5rgHSgl6q2A+4DPg1S04wxIRapoXI45zDVK1UnvlJ8wetwE8yeShdgq6puV9VcYBLQu9g2vYFP1GcJUFNEGp6gbG9gvPN8PNAHQFVXqeoeZ/kGoLKIVApS24wxIRSpoZKZm0l8XDzxcb5QsTmVohoDfxR6neIsC2SbssrWV9W9AM5jvRKOfRuwSlVziq8QkSEislxElqelpZ1Ec4wxbhGpoeLvqdjwV8mkhGXFT7oubZtAypZ8UJE2wOvAAyWtV9WxqtpJVTslJCQEsktjjMtEaqhk5vjmVGz4q2QpQNNCr5sAewLcpqyy+50hMpzHVP9GItIE+Bq4V1W3lUMbjDEuFLGh4gx/FfRUbPiriGVAooi0EJE4oB8wo9g2M4B7nbPALgUOOUNaZZWdgW8iHudxOoCI1AS+BZ5R1UVBbJcxJsQiNVT8w19VYqoQJVFh2VOJOfEmp0ZVPSIyFJgDRAPjVHWDiDzorP8AmAX0BLYCWcCgsso6ux4OTBGRwcAuoK+zfChwLvC8iDzvLOuuqgU9GWNMZIjUUMnM8fVURITqlaqH5ZxK0EIFQFVn4QuOwss+KPRcgYcCLesszwC6lbD8FeCV06yyMSYMRGKoeNVb8D0VgPi4+LAMFftGvTEm7ERiqBzN9V3nyz+fEl8pPiyHvyxUjDFhJxJDxd8r8X9HpXql6jZRb4wxFSESQ8XfKynoqcRZT8UYYypEJIaKv1fin1MJ14l6CxVjTNgpKVSio6KLrAs3xYe/bE7FGGMqSEmhEiVRRElU2IZKScNfNqdyhjiUfYjpm6aTnpUe6qoYc0YqKVT8r8M1VEob/gq3WwpbqJyC5Ixk+kzuw8JdC0NdFWNKpKq8vfjtiP3gE4mh4u+pFAx/xcXjVS9ZeVmhrNZJs1A5BW0S2iAIa/atCXVVjCnR+tT1PD73cT5dE5m3FYrEUPHPqfiHv8L1SsUWKqfgrLizOLf2uaxNXRvqqhhTok3pmwBfrzoSRWSo5GQSLdFUjqkMELZXKrZQOUUXNriQtfstVMoyfdN0Gr3VKCwnG8OdP1T8j5HGHxz+M778wjlU/BeTFPHd+SNcr1RsoXKK2tdrz7YD2ziSeyTUVXGteTvmsffIXlbvWx3qqpxx/D2USO6p+M/2KiycQ6Xwdb/gP3MrNvx1hmhfvz2Ksj51fair4lrrUtcBWKiEgL+Hsu/IvrAbPgmEx+s5bugLnFDRMA6VuEKhYsNfZ5YLG1wIYENgpVBV1u33hcqa/XZCQ0VSVZIzkjm7xtkAJKdHXm+lzFAJ056Kf/jLr/jw18a0jbQe1Zrdh3eHpH6BslA5Rc1qNCM+Lt7OACtF6tFUMo5lANZTqWh7MvdwJPcIN593MxCZQ2CRGCr+Wwn7+Xst/p7KzM0z2Zi+kZ9+/ykU1QuYhcopEhHa129vZ4CVwj8s2KFBB9anrg/bP/Rw5A+Rnok9iZZo66mEicM5h4sMfxU/pXjZnmUArNq3quIrdxIsVE7DhfV9Z4CF2zdeK4I/VO5pdw85+TkR+cZ2st7/9X3GrRoX9OP451Pa129Pi1otrKcSJjJzM4sMf1WNrVrklsJLdy8FYOXelSGpX6AsVE5D+/rtOZxzmF2HdoW6Kq6zPnU9davWpfs53QEbAsv35vOPn/7BCz+9EPQPIcnpyVSLq0aj+Ea0qtMqYkMlNir2uOVhHSo5RSfqRYRqcdXIzMlk/5H97Dy0k0rRlVi1b5WrP8haqJyG9vXbAzYRXZL1aetpW68t59c9n7jouDP+Z7R632oOZh8k5XBKwVlxwbIpYxOt6rRCRGhVpxVbMrbgVW9Qj1nRPBpZPRVVPa6nAv+5/pd/6Ov21rdzMPsgOw/tDEU1A2Khchra1W8H2Blgxan6TrVum9CW2OhY2iS0CWlPZeyKsdwz9Z6QHR9839nx+3bzt0E91qb0TZxf93wAWtVtxTHPMf449EdQj1majKwMnv/x+YJb5ZaXSBv+ysrLwqveIhP18J8bdS3dvZQoiWLwRYMBWLXXvfMqFiqnoVpcNc6pdY6FSjG7Du3iSO4R2tZrC/gm61fvWx2SLruq8vqi15mwbgLb/9xe4cf3+3HHj7ROaE3Hhh2ZtXVW0I6TlZfFrkO7aFWnFUDBY6iGwN5a/BavLHiFD5Z/UK77jbRQKX4vFT9/T2Xp7qW0rdeWS5pcQpREuXqy3kLlNLWv3z4oQzvZnmz+PPZnue+3Ivgn6QuHSlpWGvuO7KvwuqzYu6IgTKZvml5u+913ZB9NRzbly9++POG2ufm5LNi1gGuaX8ONiTfyyx+/cODYgXKrS2GbMzYDFOmpQGi+q3Is7xhjV4wF4O0lb5PjySm3fUdaqBS/l4pffKV4DmUfYtmeZXRp1IWqsVU5v+75FiqR7ML6F7IlY0u5X576/m/up/0H7cv1D7Gi+EOlTb02gO9nBKGZrJ+yYQoxUTG0rNWS6cnlFyojFo0g5XAKI34ZccJtl+5eSlZeFte0uIaeiT3xqpe52+aesFx6VjozN888qR6ePzz8YVL/rPrUqFQjJNcAm7h+IhnHMnj2ymfZk7mHT9eW3xWTIy1Uit9LxS8+Lp4NaRs4cOwAXRp3AeCiBhfZ8Fck81+uZfEfi8vc7u3FbzMjeUZA+9x1aBcT100k5XAKUzZMKY9qVqj1aetpUr0JNSvXBP5z9YGKnqxXVaZsmEL3c7pzV9u7WLBrwUnfX2TXoV3cPPHmgqsDAOw/sp8xy8eQUDWBpbuXnvAUzx93/IggXNX8Kjo36kzdqnWZteXEQ2D3f3M/vSb24tUFrwZc303pmxCExNqJgO8MolZ1K/4MMFXlvV/fo3399rxyzSt0bNiRNxa9Qb43v8xy2Z5sek/qzUs/v0Refl6p27khVDxeDwOnDQyot3oipfVUqleqXnB9wcKhsjtzN2lH0077uMFgoXKaOjXqhCBc++m1XDDqAh6Z/Qh7MvcU2Wb2ltk8Pvdxek/qzRuL3jjhJ8/3f30fgOY1mzNyycjTmovIzMnk7cVv89T3TzF01lAenPkgy3YvO6V9bTuwjY1pG0+43frU9bSr167gdc3KNWlWo9kp91RUlRGLRjB90/ST+lks3b2UnYd2cmebO+l9fm+86j3pSfJ//PsffLP5G26dciuHsg8BMOKXEeTk5/DtXd9SJaYK/1r+rzL38eOOH+nYsCO1q9QmOiqaHuf2YPbW2WW+wa7au4ppm6Zxdo2zef7fz/POkncCqm9yRjLNajajSmyVgmWBnlb8W9pvJ3V6/IFjB1i0a1GJ6+bvnM+a/Wt4pMsjiAhPX/E0Ww5s4etNX5e5zxGLRjAjeQYv/PQCV358ZcFwXnGBhMofh/7gh+0/BNyek/XukncZv2Y8A6cNPO35utLmVPyvq8RUKej5X9TwIsC9X4K0UDlNTWs05beHfuOt7m/RvGZzxq4YS6+Jvcj2ZAO+T14Pz36YVnVacWebO3nqh6d4aNZDpX6ayszJZOzKsfRt05dnrnyGVftWsWDXglOq2w/bf6DtmLY8Pvdx3v31XSaun8iEdRO4fNzlvPXLWyd1mumCnQvoOLYj7T9oX2ZZj9fDxrSNBfMpfh0adDjlnsq4VeMY9sMw+kzuww0Tbij1jaa4yRsmExcdR+9Wvbm44cU0jm/MtORpAR93U/omPl37Kdefcz07/tzBwOkD2XdkH6OXjebudnfTuXFn+rXtx4R1E0q96F9WXhaLUxZzTYtrCpb1PLcn6VnpLN+zvNRjJ/2cRI1KNVg5ZCW3XXAbj855lI9WfhRQnf3zKX6t6rQi5XBKmWdg7fhzB5d8eAn/9fF/BXQBQ4/Xw02f38SVH1/J24vfPm79e0vfo3aV2tzV7i4Abr3gVhJrJzJ84fBSPxj8fvB3/rnwn/Rt3ZfJt09mS8YWLvrXRfT9oi8PznyQ5358jiUpSwqOX1aobEzbyCUfXsJ1n15XYv1Ks//I/hP2pgB2HtzJP376B1c1u4roqGgGThtY8Dfh8Xp4Y9EbfLb2s4CPW9rwl7/ncnGjiwva26FBB8C9Z4BZqJSD8+uez2OXPcbsu2fzRd8vWLl3JUNnDQXgzV/eZNuf23j/hvf5/LbPeeqKpxizfAznvHcO90y9h9HLRhf5dDhu1TgO5xzm0UsfZUD7AdSpUueEn1JVleELh1P79dq0H9Oee6bew91T7+a6T6+jSkwVfvmfX8h+LpuMYRns+tsuep3Xiye+f4KbPr+J/Uf2n7B9s7fM5vrPrqdhtYbcmHgjT3z/BDdPvLnEoaRtB7aRk59zXKhcWP9CktOTT7rLvvPgTh6d8yhXNbuKd65/h8Upi2k7ui33fn0vX/32Van3mvCqlykbptDj3B7UqFwDEaF3q97M3TaXY3nHAjr2iz+/SJWYKnx6y6e8cd0bTNs0jf8e/9/k5OfwXNfnAHiw04MczTvKhLUTStzHol2LyM3PLRIq1597PVESxbdbSu41rdizghnJM3jssseoU7UOE26dQI9ze3D/N/fz5i9vlvqm7FUvyRnJBWd8+fnnV0oLY696GTR9EKpKyuEUnpj7RME6VSXppyQGTx9cZN7wlfmvsDhlMRc3vJjH5z7Oq/NfLdj+599/ZtqmaQzpOKSgxxQdFc2wK4axYu8Kmr/bnDu/vJN3lrxT5Hfo0TmPEiVRvNX9Le5ocwfr/rqOXuf1Yn3qeqZunMrwhcO5YtwVPP/j8xzLO1ZqqOzN3MvV46/Gq15uTLyRx+c+zusLXy+x7YV/Bo/PeZwGbzUgYUQCfb/oy4crPyz4cFiYqjJ0tu/ve3yf8bzX4z0W7FrAu0veZf+R/XT/tDtP/fAUA74ewOhlo0s8XmZOJs/Oe5Z+X/bj15Rfy5yoB+jcqHPBstpVatOsRjNW7vMNu+7J3MPg6YPdc3tzVQ3aP6AHkAxsBZ4uYb0A7znr1wIdT1QWqA18D2xxHmsVWveMs30ycP2J6nfxxRdrMDz7w7NKEvrCv1/QKq9U0dun3F5k/eT1k/W2ybdpgzcbKElolVeq6MjFIzXHk6Mt3mmhV3x0RZF9SZLotgPbNC8/Tz9Z/Yk+POthnbN1jubl5+nh7MN62+TblCS0+6fd9cYJN2rTt5tqzEsx+sScJzQrN+u4+nm9Xh29dLRWermS1hpeSz9c8aF6vd7jtsvMydRRS0dpzEsx2vFfHTX1SKp6vV59/9f3Ne7lOK01vJY+88MzuufwnoIyn6/9XElCV+xZUWRfv+z6RaNejNK6b9TVscvHqiffc8KfY743X68Zf41W+2c13X5gu6qq7svcpw9884DWfr22koTGvRynt0y6RedsnaP53vyCsgt3LlSS0AlrJxQsm7N1jpKEztg044THXrNvjZKEPvvDswU/M//P+Z6p9xT5WV70wUXabnS7gp9hjidHcz25qqr69PdPa8xLMZqZk1lk/10/7qrV/llNX53/qh7NPVpk3U2f36Q1h9fUg8cOFizLys3SvlP6KknoX6b/pWD/qqqpR1J19pbZ+ty855QkdMyyMUX2t3bfWiUJfeaHZ3RD6gbN8eQUWT9y8UglCf1o5Uc6bO4wJQmdvWW25nvz9a8z/6okoSShl314maYfTddFuxZp1ItROmDqAM3Lz9MBUwcoSWifSX20xTstlCS01vBauuvgriLH8eR7dMyyMXrHF3dos5HNlCS0xms1dPiC4frVb18pSehrC14r9f/kcPZhHTRtUEF9uo3vdtw2d311l5KENnqrkW5K26R5+Xna78t+ShL60LcP6Vu/vKWv/PyKjlg0Qjenby74//KXu+/r+3TQtEHa5O0mShLa4YMOBdv5+ev65qI3VdX3O3DzxJu10suVtOGbDbXyK5X1wxUf6s0Tb1aS0NFLRxeU9Xq9+vnaz7XRW40K2k8S2vDNhkoSeiTnSJFjjVo6SklCJ66bWGR5n0l9NPG9RE1OT9bm7zRXktCYl2L0vSXvlfi3XN6A5VrK+6pokL47ICLRwGbgOiAFWAb0V9XfCm3TE3gY6AlcAryrqpeUVVZE3gAOqOpwEXnaCZWnRKQ1MBHoAjQCfgDOU9VS+7KdOnXS5ctLH4I4VfnefHpM6MEP23+gamxVNj20iaY1mh63naqy5cAWHpvzGN9u+ZaWtVqy/c/tfHXHV9x6wa0A7D68m+bvNqdrs678fvB3tv+5vaCLX/+s+lSLq8aOgzt449o3eOyyxwruGpfvzT/urnjFbUrfxAMzH2D+zvl0bdaVO1rfQWx0LILw086fmLZpGll5WVzV7Cqm95tOjco1Csqu3b+WF39+ka83fk1MVAwdG3Zkx8EdpB5NJTYqloNPH6RqbNUix1u9bzUPz36YhbsWclGDi+jdqjedG3emQ4MOZHuyST2aSnpWOmfFnkWdqnWYu20uT37/JGNvGsv9F99fZF8er4df/viF6Zum8+naT0nLSuOcWudwaZNLOZh9kI3pG9mTuYfUJ1ILPu3l5ueSMCKB7ud0p3vL7szcMpO1+9dSLa4aNSvXpP5Z9bm6+dX0OLcHT37/JP/e8W92/O8OalWpBfgmU19b8BpDuwylcfXGBXUZu2IsD8x8gNtb386WjC1sSNuAx+vhrNizyPPm0blRZxb+T9FPkb8f/J1H5zzKtE3TaBzfmAcufoBaVWqR48nhie+f4OX/frmgN+TnVS//+Pc/eHXBq3Rs2JHKMZVJTk8uuBo0+HrNM/rNILFOYsGybE82Z488m7QsXy8xJiqGrs260q9NP9rUa0O3T7pxbctrmdFvBjn5OVw89mIOZR+iW8tufLLmE4ZdPowujbtw99S7aVGrBdmebARh9YOrqV6pOl718teZf+WjVR9xbctr6de2H33O71NwokZpNqRu4Jl5z/DN5m8AOK/Oeaz76zriouPKLPfFhi8YMnMI17a8li/6flFk3bPznuXzdZ/zw70/cG7tcwt+V/4y4y+MXzP+uH11btSZuOg4Fv2xiNe6vcZTVzyFiKCqzNw8k4HTB5KXn8foG0dTvVJ15m6by8T1E2lavSnLhywv6C3tO7KP9mPaU6NyDb664yva129Pbn4ut0+5nW82f0Ov83qRejSV7X9uJy0rjY4NOzKq5yjaJLTh/aXv+3qgKAeGHSj4Gwb4but33DL5FjYP3VzkPeSln1/ihZ9eIKFqAooy8baJvPvru8zcPJMB7QfQM7EnGVkZZBzLYG/mXlIyU9h9eDeZuZnk5eeRm59Lr/N68a9eZc8HlkZEVqhqpxLXBTFULgOSVPV65/UzAKr6WqFt/gX8pKoTndfJwNVA89LK+rdR1b0i0tAp36r4/kVkjrOPUk/LClaogO900J4TejL4osE80OmBMrdVVT5f9zmPfPcIdarUYeNDG4sEwoCvB/DZ2s/o3Kgzz3V9jutaXsesLbOYsG4CWw9sZeT1I+nWstsp1dOrXj5e9TFPfv8kf2b/53sxtSrX4o42d3BP+3u4vOnlx91hz2/bgW28s+Qd1uxfw3l1zuP8uudz5dlXcmmTS0tt68T1E3l90eus278Opezfvx7n9mDWXbOK/KEVl+PJYerGqYxdOZadB3dSq0otalWuxU3n3cTfLv1bkW37f9WfSesnAXB2jbO5vOnlZHuyOZR9iN8P/s6OgzsKtn3p6pd4/qrny6wfwJHcIyS+n0hefh4XN7qYjg06UjW2KgezD3Iw+yD92/Xn2pbXllh2/s75DPt+GL/u/rVgWULVBLY+svW4oRC/8avH89rC12hQrQGt6rSiVd1WXNTgIjo27Fgk+As7lneMjekb+S3tN9bsW8P05OlsObAFgDpV6rD+/6ynQbUGACzfs5xLP7yUfM3n+a7P8+LVLyIizN85n5sn3syR3CMsGLSAy5pedtwxCp8gEKiff/+ZkUtGMuyKYVze9PKAyvx57E+io6KP+xmpqu+6YNHHXxcsIyuD2OhYKsdUJvVoKpPWT2LCugkkpycz+sbRDOww8Lgyuw7tot+X/Vic4nsbqRpblaubX82I60bQOqH1cfs/K+6sgnvMg+938/5v7mfhroW0rNWSFjVbcOXZV3JP+3uK/I0fzjnMn8f+pFnNZse1p6TLt8zcPJNeE3vRrEYz5g6Yy3l1zsOrXl7++WWSfk4qsm3dqnVpUr0JjeMbU6NyDWKjYomLjqNL4y78peNfSv8hlyFUoXI70ENV/+K8HgBcoqpDC20zExiuqgud1/OAp/CFSollReSgqtYstI8/VbWWiPxfYImqfuYs/wiYrapFzvcTkSHAEICzzz774p073XMNnUPZh/B4PdSpWue45ckZyXRu1LnMN9fTkePJ4VCO7/ger4cG1Rqc8BPj6crMyWTl3pWsS11HfFw89c6qR+0qtcnKyyLjWAZZeVn0Ob9PqW+up2LbgW3M3DyTbi270SahzXE/z60HtjJn6xw2Z2zm1W6vUi2uWkD7zffmEyVRp/z/k5WXxdHcoxzNO0qNSjUKekfBoqqs3reaqRun0q1lN65ufnWR9Z+t/YxjeceO6yFuO7CNlMMpXNX8qqDWryJ51VvqhyaAvPw8pmyYQqP4Rlze9HIqxVSqwNqVLDc/l/d/fZ/+7frTKL5RkXXb/9xOtiebOlXqULtK7RID9nSFKlT64pvXKBwMXVT14ULbfAu8VixUhgEtSytbRqiMAhYXC5VZqvpVaXUMZk/FGGMiVVmhEsyzv1KAwhMJTYA9AW5TVtn9zrAXzmPqSRzPGGNMEAUzVJYBiSLSQkTigH5A8a+UzwDuFZ9LgUOquvcEZWcA9znP7wOmF1reT0QqiUgLIBFYGqzGGWOMOd7xJ3qXE1X1iMhQYA4QDYxT1Q0i8qCz/gNgFr4zv7YCWcCgsso6ux4OTBGRwcAuoK9TZoOITAF+AzzAQ2Wd+WWMMab8BW1OJRzYnIoxxpy8UM2pGGOMOcNYqBhjjCk3FirGGGPKjYWKMcaYcnNGT9SLSBpwOl+prwuc3F2fwt+Z2GY4M9ttbT5znGy7m6lqQkkrzuhQOV0isry0MyAi1ZnYZjgz221tPnOUZ7tt+MsYY0y5sVAxxhhTbixUTs/YUFcgBM7ENsOZ2W5r85mj3NptcyrGGGPKjfVUjDHGlBsLFWOMMeXGQuUUiEgPEUkWka0i8nSo6xMMItJURP4tIhtFZIOI/K+zvLaIfC8iW5zH4N6iMEREJFpEVjl3J434dotITRH5UkQ2Of/nl0V6mwFE5FHn93u9iEwUkcqR2G4RGSciqSKyvtCyUtspIs8472/JInL9yRzLQuUkiUg0MAq4AWgN9BeR1mWXCkse4HFVvQC4FHjIaefTwDxVTQTmOa8j0f8CGwu9jvR2vwt8p6rnAxfia3tEt1lEGgOPAJ1UtS2+22z0IzLb/f+AHsWWldhO5++8H9DGKTPaed8LiIXKyesCbFXV7aqaC0wCeoe4TuVOVfeq6krneSa+N5nG+No63tlsPNAnJBUMIhFpAtwIfFhoccS2W0SqA12BjwBUNVdVDxLBbS4kBqgiIjFAVXx3i424dqvqfOBAscWltbM3MElVc1R1B777XXUJ9FgWKievMfBHodcpzrKIJSLNgYuAX4H6zt05cR7rhbBqwfIOMAzwFloWye1uCaQBHztDfh+KyFlEdptR1d3Am/hu9rcX351n5xLh7S6ktHae1nuchcrJkxKWRex52SJSDfgK+JuqHg51fYJNRG4CUlV1RajrUoFigI7AGFW9CDhKZAz5lMmZQ+gNtAAaAWeJyD2hrZUrnNZ7nIXKyUsBmhZ63QRflzniiEgsvkCZoKpTncX7RaShs74hkBqq+gXJFcDNIvI7vqHNa0TkMyK73SlAiqr+6rz+El/IRHKbAa4FdqhqmqrmAVOBy4n8dvuV1s7Teo+zUDl5y4BEEWkhInH4JrRmhLhO5U5EBN8Y+0ZVfbvQqhnAfc7z+4DpFV23YFLVZ1S1iao2x/d/+6Oq3kMEt1tV9wF/iEgrZ1E34DciuM2OXcClIlLV+X3vhm/uMNLb7VdaO2cA/USkkoi0ABKBpYHu1L5RfwpEpCe+cfdoYJyqvhraGpU/EbkSWACs4z9zC8/im1eZApyN74+yr6oWnwCMCCJyNfCEqt4kInWI4HaLSAd8JybEAduBQfg+dEZsmwFE5EXgTnxnO64C/gJUI8LaLSITgavxXeJ+P/ACMI1S2ikifwf+B9/P5W+qOjvgY1moGGOMKS82/GWMMabcWKgYY4wpNxYqxhhjyo2FijHGmHJjoWKMMabcWKgYY4wpNxYqxhhjyk1MqCtgTKQSkeeBu/FdnC8dWAEcAobg+5LhVmCAqmaJyP8DjgHnA83wffnwPuAy4FdVHejsszvwIlAJ2AYMUtUjIjIcuBnfl9XmquoTFdRMY4qwnooxQSAinYDb8F3d+Vagk7Nqqqp2VlX/PUsGFypWC7gGeBT4BhiJ754W7USkg4jUBZ4DrlXVjsBy4DERqQ3cArRR1fbAK0FvoDGlsJ6KMcFxJTBdVY8BiMg3zvK2IvIKUBPf5UDmFCrzjaqqiKwD9qvqOqfsBqA5vgv7tQYW+S5VRRywGDgMZAMfisi3wMzgNs2Y0lmoGBMcJV0+HHx34OujqmtEZCC+6zH55TiP3kLP/a9jgHzge1Xtf9zBRLrguyBiP2Aovh6PMRXOhr+MCY6FQC/nnufV8N1JEiAe2OvcVuDuk9znEuAKETkXwLm67nnO/muo6izgb0CH8miAMafCeirGBIGqLhORGcAaYCe++Y9DwPP4rvS8E98VoONPYp9pTu9moohUchY/B2QC00WkMr4e0qPl1Q5jTpZdpdiYIBGRas6ZWVWB+cAQVV0Z6noZE0zWUzEmeMaKSGugMjDeAsWcCaynYowxptzYRL0xxphyY6FijDGm3FioGGOMKTcWKsYYY8qNhYoxxphy8/8DClfALqyiWVYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(loss_buffer, color='g', label='loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('games')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEGCAYAAABsLkJ6AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAqKElEQVR4nO3deXwcd33/8ddH92XL1uFTvmPHzuHYiTAJJIZACiGEHJxpQxOgYJI2hYTmV0oDbVKaR0mAUiiFYCBAmyaFlgRIIDQHIUcLOHawHceX4iuWLNuSJfnQarXX5/eHRq5sS7YkazWr3ffz8dDDq9ndmc+O1vOe73dmvmPujoiI5J68sAsQEZFwKABERHKUAkBEJEcpAEREcpQCQEQkRxWEXcBQ1NTU+OzZs8MuQ0RkTFmzZk2ru9ceP31MBcDs2bNZvXp12GWIiIwpZrarv+nqAhIRyVEKABGRHKUAEBHJUQoAEZEcpQAQEclRCgARkRylABARyVFj6joAEZFstLOri2cPHuRwIsFHpk6lLD8fAHenORZjY2cnF4wbx8TCwhFdrgJARIYsmkzyZHs7qw4fBuB9tbUsrqgIuarR5e785tAhOpNJ6oqLWVhWBsC+WIzt0Shnl5dTWXDqTeyv29u58uWX6UylAPju3r3ct2ABKXf+tKGBtUeOAPDYuefyzurqEf0MCoCQdadS/Gj/fsrz87m6poZ8s1FZ7mvRKN2pFPODL61kj8OJBLuiUc7ps0HuvfGTneb3y915aP9+Pvnqq7TG4/TO7auNjTx27rksGzeOkmDvNZttjUS4aetWnunoODptdkkJHYkEHYkEAIVmXF1Tw5fnzWNmSQkA8VSKV7u62BiJsKmzk42RCD9pbWVOSQn/cdZZ7IxG+eCmTVz40ksATCsq4ivz5rG4ooILxo0b8c+hAAhJJJnkO83N3PvaazTFYgAsKC3lg5Mnc+OUKUe/MMPxSmcnu6JRivPyWFBaSl1x8dH/+AcTCW5paODBfftIAQvLyrigooJl48dzbU0NM05juTI6Uu7kDbAh//Lu3dy9axftiQTfnD+f88eN4xtNTfz0wAHeNnEiD5511oA7GX1Doj0ep6m7m7PLyzEzIskk/7h7Nw/u38+mSIRl48bxrwsX8taJE2mJx3nL2rW8ae1aAG6aNo1vLlgw7M/n7jzd3s66zk4ur6rirLKyEQmu3s82HCl3Ll27lu3RKIvLy/llWxsV+fl8ff58zisv5+XOTp5qb2dSURFnlZUxs6SE5zo6uG/PHn7Z1sblVVW4O79sazu6pw8wq7iYK6ur+Zf586ktKuLcigo2L1vGCwcP0hKP80eTJjFhhLt9+rKxdEvI+vp6H+tjAb3S2ckXXnuNR1tbOZhMsryyks/OmkVHIsFXGxv530OHqCoo4MnzzmNpkPiHEwk2RSJEUykWlZVRW1TU77yPJBJ8evt2vrFnzzHTZxUX8/5Jk/jcrFnctHUrP9y/n9tmzGBmcTG/aGtjQ2cnjd3dAHx86lTumTdvUE3XbBZPpWjo6qItHueiyspTtsxS7rx4+DBPtLVRVVjIjOJi8s2oHzeOQjMe2r+f+nHjeP348QC0xGL8tLWVRw8coLKggPfX1vLO6upjNlDuzv8cPEhtURGFZvzPwYN8cfduulMpnjzvvBN2Eh5tbeWqDRu4vKoKgF+2tQFQmZ/PsvHjebK9nffV1hJ3J5pKMbO4mF3RKGeUlvKn06fzsS1b2B+P86m6Ov5u1y72xmLMLC5m2fjxvHT4MNujUd48YQLXT5rEh6dOPWad7I/FeGDfPtYcPsyD+/fzn2edxXsnTeInLS18ubGRaCrF2WVl3D5jBrNKSijNyyPmzt27drHq8GHOLC3lD6qqyAPu3rWL3wVdSwBnlpbyh5Mnc/uMGZSfonXh7qTgaG3PdXRwx44drD1yhKqCAr6xYAFXVFUNOQge2LuXP968mYvGj2dXNMp1kybx/2bMYEpx8Unft6Ori8/u2MGqw4fpSia5srqaiysrWVRezsKyslN+npFiZmvcvf6E6QqA0eHu/MNrr3Hnzp2U5eXx7tpaPjxlCpdMmHDM67ZEIrxt3ToOJhJcXlXF/nicZzs6SPV5zRfnzuX2mTOPeV8sleKK9ev5VUcHn6yr47pJk4gkk2yMRPhlWxu/OHCAacXFNHZ3c9fs2fzNcaOqbo1E+EZTE//c1MT548ax6vzzT3uvKx0SqRT5ZgPW1hCJcO/u3VQVFHDPvHknndehRILeb39pXh5FeT0nxe2LxXjT73/Plq4uoGcD9MV583hXTc0J89je1cXXGhv5r5aWoy25vgwoycujK5XCgKtratgXi/G7Q4dI0RPOh5JJ2hMJLps4kW8tWMDc0lIAvtvczEe3bDlmfovKytjT3c2EggIeO/fco908nckkZ69aRUV+Pr+vr8eBv96+nclFRdw0bRrjCgr4i1df5R8bG6krLqamsJDd0SgzSkp4+cgRkkB5Xh6TiorYEY0yr6SE22bM4Fft7azv7KQsL4+vzZ/Pm477vh4vnkrxht//ns2RCLOKi3klEuHM0lLmlJbyXEcHkWDvt9CMivx82hMJzisvZ1s0ypFkEujpSvmrmTO5vKqKXxw4wI9bWni6o+NoN8myIESPX+53m5v5wmuvsTcWY15pKYVmrOvsZHZJCe+qruZX7e28EolQVVDAH0ycyHfOPJOKQezoRJJJzly1ismFhay64IIBW1+ZTAEQopQ7n2ho4F/27OH9tbV8PWjuDWRXNMqnXn2VtUeOUJqXx9U1NSwbP56SvDzu27OHn7S28v2FC7lxyhSg5wv6J1u28B/79/ODhQu5IZje19Pt7bz/lVc4o7SUF5YupTCv/zOA/6WpiVsaGlh9wQXD7nMcqf7m423v6uKydevoTqV4/6RJ3Dl79tGWirvzj42NfHrbNhxIAQ8tWsR1kyf3O5+btm7lyfb2o9Mq8vP5hzlzeGNlJSu2buWVzk6+esYZlOblcc/u3Wzo7OQvZ8zg9ePHsy8WY2MkwsbOTp7t6CDfjCuqq3l3TQ1XVlfTlUqxp7ubaCrFU+3t7I/HuXHKFB7Yt49HWlqYW1rK8spK3lNby5KKChLufLe5mb/cvp2kO383Zw7X1tTwujVrWFRWxsemTSPhztllZSwbP561R45w+fr1dCQSXD95MkVmPNnezo5olOeWLDlhp6Lv32V7NMrckpJj/jYvHT7M15uauK2ujjNKS/mvlhaurK4e9hkn27q6uGP7djpTKZZXVnJrXR2FeXm0xmL8qKWFrlSKlliMxu5u/mTqVC6dOJF4KsUzHR0cTia5qrr6hO/ncx0d3Lh5M13JJC/V1zMt2PNOBa2kTwT/Xy4cP56LKyvZ1tVF3J3F5eX89axZlOfnE0ul+P7evaw6dIjv793L68eP54dnnUVdSQlHEgk2B63sN1ZWHl0/7s4NmzfzwL59PLtkCctPEYCZSgEQkt3RKB/fupXH29r4i7o6vjhv3mltGLtTKS5fv55fd3RwcWUlSyoqePzAAbZFo3xh7lw+fVzLoK9DiQSFZpSepNnZHo8z5X//l5unTeOf5s8fVo1vWbuWndEod8yaxUemTDmtzxtPpXjh4EFeOnKEr+zeTVcqxfIJE3i0tZX5ZWW8o6qKZ4MNR0NXF++uqeGf58/nPa+8wpZIhL+ZNYvpxcV0pVL8d1sbzx08SGN3N+Py87m1ro6JQYD8sq2NJ4JAyAMeOeccrgr2+KPJJH/a0MD39u49WldFfj6Lysp404QJ3FZXd3SDdDoao1FubmjgsQMHACgwY119PWeVl5/w2tZYjE9t23b0ta8fP56PTp3Ke2pPGPI9a2zs7GTZmjWcUVrKxZWVNHZ38+Lhw+yJxZhSVMS/zJ/PtTU1g/q+/bilhes2biThztSiIpr7tN7OKy9nZkkJe2MxSvPyeO7gQe6eM4e/njUrnR8vrRQAaZRIpbj7tdd4vqODI8kkZ5aVcVZ5OXtjMb61Zw8GfGHuXG6ZPn1E9oqjySTfbm7ma01NtMXj1BUX809nnMGlEyee/ocB3rthA88fPEjjRRdRmJfH7miUL+/eTUNXF/ctWHDSA8UNkQgLVq1iUmEh++NxvnbGGfx5Xd2glns4kaA8P588M9ydb+3Zwx07dtAWnFUxr6SEh885h8UVFfy6vZ33bdzIwUSCSyorqSwoYHllJZ+sq8PM2BqJ8Pb169kZjR6df3VBAW+vquLc8nKunzz5mM/h7jze1kYkmaR+3DhmB90wfZ9/tauLSCpFdUEB0/scWB9JvacWPtzSwtnl5Xx46tQRX8ZY9uOWFv68oYHuVIrJRUWcW17OldXVXFNTw7ghHrd6NRLhRy0tbI5EOLOsjEVlZRwMjsUlgSlFRezo6uK9tbX8w9y5GdklOlgKgDR6cN8+rt+0iaUVFUwsKGBzJMKeWIx84PrJk7lz9mzmHLdByWQ/bW3lmg0bmFtSQmcyyb54nHygOC+Pivx8Ph90UfTXjfX3O3fyuZ07ee3CC7l561Z+1dHBf519Ngl3Lho//pj3vBqJ8I09e/j9kSNs6uxkXzxOSV4eC8vKmFBQwK87OnjrhAn82fTpLJ8wgerjuiSiySRx95P+x98fi7E/FiPPjAWlpRQM0PUlks0UAGmScue81atJufPy61539ADRwUSCeCpFzUn6+jNVPJXiU9u2sT8WO9rV8Z7aWqKpFB/YuJGXOzspNOPDU6bwZ9Onc25wqiDAOatWMbGwkOeXLqW5u5tzXnzx6B58HnBVTQ2fnz2brzc18e3mZgrNWDpuHIvKylhQWkpLPM6mSIRtXV18YNIk/nb27FG7NkIkWw0UAKGc62dm7wPuBBYBy9w9s7bqQ/DzAwfY0NnJvy1ceMzZAWP5NMrCvDz+eYD+/3X19azv7OS+PXu4v7mZlc3NnFFayntqaijMy+OVSISvB++dWlzMM0uWsDUSYXJREb9sa+OfGhv5SWsrecAt06fzmZkzT3kqnYikRygtADNbRM+JGt8Cbh9sAGRiC+CPNm7kmY4Odl94Yc51L+yLxXikpYWHW1v5VXs7SWBJRQVPLl48YMtnR1cXX21s5IOTJ1Pfz+l8IjLyMqoF4O6bYORPEwzDnu5u5udo3/LkoiJumj6dm6ZP51AiQR6c8rzqOaWlwz67SERGVsZvtcxshZmtNrPVLS0tYZdzgn3xOJPHYD//SBtfUDCoi2pEJHOkLQDM7Ckz29DPz9VDmY+7r3T3enevr83Ac5z3Bucgi4iMNWnbZXP3y9I170zRnUrRkUgoAERkTMr4LqBMti+4enByGkfrExFJl1ACwMyuNbNG4CLg52b232HUcbr2BgGgFoCIjEVhnQX0CPBIGMseSfsUACIyhqkL6DT0tgB0FpCIjEUKgNPQ2wKYpAAQkTFIAXAa9sZiTCwooDgHLwITkbFPW67ToGsARGQsUwCchn3xuAJARMYsBcBp2BuL6QCwiIxZCoDTsE9dQCIyhikAhqkzmeRwMqmrgEVkzFIADJMuAhORsU4BMEwKABEZ6xQAw6SrgEVkrFMADJNaACIy1ikAhmlvLIYBtToILCJjlAJgmPbGYtQUFubkvYBFJDto6zVMugpYRMY6BcAw6SpgERnrwroj2BfNbLOZrTezR8xsQhh1nA5dBSwiY11YLYAngXPcfTGwFfhMSHUMi7trJFARGfNCCQB3f8LdE8GvvwXqwqhjuA4nk3SlUhoGQkTGtEw4BvAR4PGBnjSzFWa22sxWt7S0jGJZA9M1ACKSDdJ2U3gzewqY0s9Td7j7T4PX3AEkgH8faD7uvhJYCVBfX+9pKHXIdBWwiGSDtAWAu192sufN7EbgSuCt7p4RG/bBUgtARLJB2gLgZMzscuDTwJvcPRJGDadjrwJARLJAWMcAvg6MA540s7Vmdl9IdQzL3liMfKBaB4FFZAwLpQXg7meEsdyRsi8eZ1JREXlmYZciIjJsmXAW0JizLxZjkvb+RWSMUwAMw4F4nBoFgIiMcQqAYWhLJKhSAIjIGKcAGIa2eJyqglAOn4iIjBgFwBC5u1oAIpIVFABDdCSZJOGuFoCIjHkKgCFqS/SMYacWgIiMdQqAIWqLxwHUAhCRMU8BMERqAYhItlAADJFaACKSLRQAQ6QWgIhkCwXAEPW2ACaqBSAiY5wCYIjaEglK8/Iozc8PuxQRkdOiABiidl0FLCJZQgEwRLoKWESyhQJgiDQOkIhki1ACwMw+b2brg7uBPWFm08KoYzjaEgkmqgUgIlkgrBbAF919sbsvAR4D/iakOoZMLQARyRahBIC7H+rzazngYdQxHDoGICLZIrRdWTO7G7gBOAhcepLXrQBWAMycOXN0ihtAVzJJVyqlFoCIZIW0tQDM7Ckz29DPz9UA7n6Hu88A/h24ZaD5uPtKd6939/ra2tp0lTso7boKWESySNp2Zd39skG+9EHg58DfpquWkaJxgEQkm4R1FtD8Pr9eBWwOo46hag0CoFotABHJAmHtyn7BzM4EUsAu4KaQ6hiSvbEYAFOKikKuRETk9IUSAO7+njCWe7qaFQAikkV0JfAQ7I3FKDLTSKAikhUUAEOwNxZjSlERZhZ2KSIip00BMATNQQCIiGQDBcAQ7I3FmKoAEJEsMWBntpmdf7I3uvtLI19OZtsbi/GG8ePDLkNEZESc7Gjml4N/S4B6YB1gwGLgd8DF6S0ts8RTKVricXUBiUjWGLALyN0vdfdL6TlP//xgOIYLgKXAq6NVYKbYH1wEpgAQkWwxmGMAC9395d5f3H0DsCRtFWWo3ovAphYXh1yJiMjIGMwJ7ZvN7DvAA/QM2/xBYFNaq8pAzd3dgFoAIpI9BhMAHwJuBj4Z/P4c8M10FZSpNAyEiGSbkwaAmeUDjwUje35ldErKTAoAEck2Jz0G4O5JIGJmlaNUT8ZqjsWYWFBAcZ4unRCR7DCYLqAo8LKZPQl09k5090+kraoMtFdXAYtIlhlMAPw8+MlpTd3dTFMAiEgWOWUAuPsPRqOQTNfQ1cX7Qr4lpYjISDplh7aZzTez/zKzjWa2vfdnJBZuZrebmZtZzUjML10OxOO0JRIsKCsLuxQRkREzmCOa36PntM8EcCnwr8C/ne6CzWwG8AfAa6c7r3RriEQAWFBaGnIlIiIjZzABUOruTwPm7rvc/U7gLSOw7K8Af0nPxWUZbWtXFwDz1QIQkSwyqLOAzCwPaDCzW4AmYNLpLNTMrgKa3H3dWLi5SkNXF/nAnJKSsEsRERkxgwmAW4Ey4BPA5+npBrrxVG8ys6eAKf08dQfw18DbBlOgma0AVgDMnDlzMG8ZcVsjEeaUllKkawBEJIsMJgAOuPsR4Ajw4cHOOLh6+ARmdi4wB+jd+68DXjKzZe6+t5/5rARWAtTX14fSXbS1q4v56v8XkSwzmAD4vplNB16kZxyg5/uODjpUwXuPdiGZ2U6g3t1bhzvPdHJ3GiIR3lSZ8xdDi0iWGcx1AMvNrAh4HfBm4OdmVuHuVekuLhM0x2J0plI6BVREss4pA8DMLgYuCX4mAI8Bz49UAe4+e6TmlQ4NvWcAqQtIRLLMYLqAngVWA/8A/MLdY+ktKbP0jgI6XTeCEZEsM5gAqAbeCCwHPmFmKeA37v65tFaWIVqDW0HWFBaGXImIyMgazDGAjmDohxn0nLHzBiBntoYHggCoKhhMVoqIjB2DOQawDdgCvADcB3w4l7qBDsTjVObnU6BrAEQkywxmt3a+u6fSXkmGao3HqVb3j4hkocHs1p5hZk+b2QYAM1tsZp9Nc10Z40A8rv5/EclKgwmAbwOfAeIA7r4euC6dRWWSA4mEWgAikpUGEwBl7r7quGmJdBSTiQ6oC0hEstRgAqDVzOYRDNtsZu8FmtNaVQZpjcep1hlAIpKFBrNl+zN6BmNbaGZNwA7g+rRWlSFiqRSHk0kdAxCRrHTSADCzfOBmd7/MzMqBPHc/PDqlha8tuAZAXUAiko1OGgDunjSzC4LHnaNTUuZoVQCISBYbTBfQ783sZ8B/AkdDwN0fTltVGeJAoudYt7qARCQbDSYAqoADHHsfYAeyPwDUAhCRLDaYsYAGfRewbHO0C0hnAYlIFtIANyehFoCIZLNQAsDM7jSzJjNbG/xcEUYdp3IgHqcsL4/S/PywSxERGXFh9m18xd2/FOLyT0nDQIhINhvMcNCf6mfyQWCNu68d8YoyiEYCFZFsNpguoHrgJmB68LOCnpvDf9vM/vI0ln2Lma03s/vNbOJALzKzFWa22sxWt7S0nMbihu6AhoEQkSw2mACoBs53979w97+gJxBq6blF5IcGepOZPWVmG/r5uRr4JjAPWELPuEJfHmg+7r7S3evdvb62tnbQH2wk7OnuZkpR0aguU0RktAxm93Ym0PcOYHFglrt3mVn3QG9y98sGU4CZfRt4bDCvHU3xVIrd3d3MKS0NuxQRkbQYTAA8CPzWzH4a/P4u4KFgbKCNw1momU11994RRa8FNgxnPum0u7ubFDCnpCTsUkRE0mIwF4J93sx+AVwMGHCTu68Onh7uqKD3mtkSeq4o3gl8fJjzSZsd0SgAcxUAIpKlBnMW0FeBH7r7V0dqoe7+xyM1r3TZ3tUFoC4gEclagzkI/BLwWTN71cy+aGb16S4qE+yIRikwo664OOxSRETS4pQB4O4/cPcrgGXAVuAeM2tIe2Uh2xGNMrO4mHyzsEsREUmLoQwFcQawEJgNbE5LNRlkR1cXc9X9IyJZ7JQBYGa9e/x/B7wCXODu70p7ZSHbEY3qDCARyWqDOQ10B3CRu7emu5hMcSSRYH88rgAQkaw2mNNA7zOziWa2DCjpM/25tFYWop3BKaAKABHJZoM5DfSjwCeBOmAtcCHwG469Q1hW6b0GQKeAikg2G8xB4E8CrwN2ufulwFJgdEdlG2W7u3tGuJilU0BFJIsNJgCi7h4FMLNid98MnJnessLV2N1NgRmTNBCciGSxwRwEbjSzCcBPgCfNrB3Yk86iwtbU3c3UoiLydA2AiGSxwRwEvjZ4eKeZPQNUAr9Ma1Uha+ruZrq6f0Qkyw3pbifu/my6CskkTbEY55SXh12GiEhahXJT+EzX2N3NdPX/i0iWUwAc51AiwZFkUl1AIpL1FADHaQpOAVUAiEi2UwAcpzcANAy0iGS70ALAzP7czLaY2Stmdm9YdRyvKdZz+2O1AEQk2w3pLKCRYmaXAlcDi92928wmhVFHfxqDFsA0HQQWkSwXVgvgZuAL7t4N4O77Q6rjBE3d3VQVFFCanx92KSIiaRVWACwALjGz35nZs2b2uoFeaGYrzGy1ma1uaUn/EES6CExEckXauoDM7ClgSj9P3REsdyI9I4u+DviRmc11dz/+xe6+ElgJUF9ff8LzI62pu1sHgEUkJ6QtANz9soGeM7ObgYeDDf4qM0sBNWTAKKPNsRjnVVSEXYaISNqF1QX0E4L7CZjZAqAICP2OY+5OSzyuUUBFJCeEchYQcD9wv5ltAGLAjf11/4y2w8kkcXdqCgvDLkVEJO1CCQB3jwEfDGPZJ9MSjwMoAEQkJ+hK4D5agwCoVQCISA5QAPTRqhaAiOQQBUAfLcEwEAoAEckFCoA+1AUkIrlEAdBHSzxOkRkVGgZCRHKAAqCP1nic2sJCTDeDF5EcoADoozUeV/+/iOQMBUAfLQoAEckhCoA+WuNxajUMhIjkCAVAH+oCEpFcogAIxFMp2hMJBYCI5AwFQKAtkQB0DYCI5A4FQEBXAYtIrlEABHQVsIjkGgVAQAPBiUiuyakA2BeLkRrgvjO6F4CI5JpQAsDMfmhma4OfnWa2Nt3L7Eommffb3/K1xsZ+n1cLQERyTSgB4O4fcPcl7r4E+DHwcLqXeTCRoDOV4sH9+/t9viUepzI/n8K8nGoUiUgOC3VrZz2jrr0feCjdy4qkUgC8ePgwr0WjJzyvi8BEJNeEvbt7CbDP3RsGeoGZrTCz1Wa2uqWlZdgLiiSTRx8/0tp6wvMaBkJEck3aAsDMnjKzDf38XN3nZX/IKfb+3X2lu9e7e31tbe2w6+ltAQA83E+QaCA4Eck1BemasbtfdrLnzawAeDdwQbpq6Ku3BfD6ceP4n4MHSbqT32fc/9Z4nCUVFaNRiohIRgizC+gyYLO7939azgjrDFoAi8rLSQL7gyt/AdydllhMF4GJSE4JMwCuYxQO/vbqbQHMKykBoLlPAHQmk3S7qwtIRHJK2rqATsXdPzSay+s9BjCvtBSAvX0CQMNAiEguCvssoFHT2wI4IwiAvi0AXQUsIrkodwIgaAHM7Q2A7u6jz+kqYBHJRTkTAJ1BC2BCQQFVBQXHtADUBSQiuShnAiCSTFJsRr4ZU4uK1AUkIjkvdwIglaIsPx+AqcXFJ7QACsyoLAjtmLiIyKjLnQBIJikLBnqbWlR0zDGA3quArc+FYSIi2S53AiCVory3BRB0AXlwbwANBCciuShnAqAzmTzaBTSlqIiYO+3BjeBb43EdABaRnJMzARBJpY7pAoL/uxagJRZTC0BEck7uBECfFsDU4mIAtkQi/O2OHeyIRpmsoaBFJMfkzGkvkVTq6F5+bwvgxs2b6UwmeVd1Nf9vxowwyxMRGXW5EwDJ5DEHgaHnPsE/OeccrqqpCbM0EZFQ5EwAdPY5DXRcQQErpk7l7VVV2viLSM7KmQDoeyEYwLfOPDPEakREwpdbB4HzcubjioicUk5sEZPudLsf0wIQEcl1oQSAmS0xs9+a2VozW21my9K5vK5gJNByBYCIyFFhHQO4F7jL3R83syuC39+croX13g9YXUAi2SEej9PY2Eg0Gg27lIxSUlJCXV0dhYO8sDWsAHBgfPC4EtiTzoX13g1MXUAi2aGxsZFx48Yxe/ZsDeIYcHcOHDhAY2Mjc+bMGdR7wgqAW4H/NrMv0dMN9YaBXmhmK4AVADNnzhzWwiJqAYhklWg0qo3/ccyM6upqWlpaBv2etAWAmT0FTOnnqTuAtwK3ufuPzez9wHeBy/qbj7uvBFYC1NfX+3BqUQtAJPto43+ioa6TtAWAu/e7QQcws38FPhn8+p/Ad9JVB/xfC6BcLQARkaPC2iLuAd4UPH4L0JDOhXWqBSAiWeTXv/41V1555WnPJ6xjAB8DvmpmBUCUoI8/XY52AakFICJp4O64O3lp2sYkk0ny07ADG0oAuPsLwAWjtbyjB4HVAhDJOrc2NLD2yJERneeSigr+af78k75m586dvOMd7+DSSy/lN7/5Dddccw2PPfYY3d3dXHvttdx1113ce++9lJSU8IlPfILbbruNdevW8atf/Yqnn36a733vezzwwAPcfPPNvPjii3R1dfHe976Xu+66C4DZs2fzkY98hCeeeIJbbrmFCRMmcOutt1JTU8P5558/Ip8zJ3aJ1QIQkXTYsmULN9xwA/fccw9NTU2sWrWKtWvXsmbNGp577jmWL1/O888/D8Dq1as5cuQI8XicF154gUsuuQSAu+++m9WrV7N+/XqeffZZ1q9ff3T+JSUlvPDCC1xzzTV87GMf49FHH+X5559n7969I1J/TgwGd/QgsFoAIlnnVHvq6TRr1iwuvPBCbr/9dp544gmWLl0KwJEjR2hoaOCGG25gzZo1HD58mOLiYs4//3xWr17N888/z9e+9jUAfvSjH7Fy5UoSiQTNzc1s3LiRxYsXA/CBD3wAgM2bNzNnzhzmB5/1gx/8ICtXrjzt+nMiAHoPApeqBSAiI6i8vBzoOQbwmc98ho9//OMnvGb27Nl873vf4w1veAOLFy/mmWeeYdu2bSxatIgdO3bwpS99iRdffJGJEyfyoQ996Jirm3vnD+k57TUntoiRVIoiMwoUACKSBm9/+9u5//77ORIci2hqamL//v0ALF++nC996UssX76cSy65hPvuu48lS5ZgZhw6dIjy8nIqKyvZt28fjz/+eL/zX7hwITt27GDbtm0APPTQQyNSd060APreD1hEZKS97W1vY9OmTVx00UUAVFRU8MADDzBp0iQuueQS7r77bi666CLKy8spKSk52v9/3nnnsXTpUs4++2zmzp3LG9/4xn7nX1JSwsqVK3nnO99JTU0NF198MRs2bDjtus19WBfXhqK+vt5Xr1495Pd9Z88efnPoEN9duDANVYnIaNu0aROLFi0Ku4yM1N+6MbM17l5//GtzogXw0WnT+Oi0aWGXISKSUdQpLiKSoxQAIjImjaXu69Ey1HWiABCRMaekpIQDBw4oBProvR9ASUnJoN+TE8cARCS71NXV0djYOKSx73NB7x3BBksBICJjTmFh4aDveiUDUxeQiEiOUgCIiOQoBYCISI4aU1cCm1kLsGuYb68BWkewnJGSqXVB5tamuoYmU+uCzK0t2+qa5e61x08cUwFwOsxsdX+XQoctU+uCzK1NdQ1NptYFmVtbrtSlLiARkRylABARyVG5FACnf/uc9MjUuiBza1NdQ5OpdUHm1pYTdeXMMQARETlWLrUARESkDwWAiEiOyokAMLPLzWyLmb1qZn8VYh0zzOwZM9tkZq+Y2SeD6XeaWZOZrQ1+rgihtp1m9nKw/NXBtCoze9LMGoJ/J45yTWf2WSdrzeyQmd0a1voys/vNbL+ZbegzbcB1ZGafCb5zW8zs7aNc1xfNbLOZrTezR8xsQjB9tpl19Vl3941yXQP+7UJeXz/sU9NOM1sbTB/N9TXQ9iF93zF3z+ofIB/YBswFioB1wFkh1TIVOD94PA7YCpwF3AncHvJ62gnUHDftXuCvgsd/BdwT8t9xLzArrPUFLAfOBzacah0Ff9d1QDEwJ/gO5o9iXW8DCoLH9/Spa3bf14Wwvvr924W9vo57/svA34SwvgbaPqTtO5YLLYBlwKvuvt3dY8B/AFeHUYi7N7v7S8Hjw8AmYHoYtQzS1cAPgsc/AK4JrxTeCmxz9+FeCX7a3P05oO24yQOto6uB/3D3bnffAbxKz3dxVOpy9yfcPRH8+ltg8GMEp7Gukwh1ffUyMwPeDzyUjmWfzEm2D2n7juVCAEwHdvf5vZEM2Oia2WxgKfC7YNItQXP9/tHuagk48ISZrTGzFcG0ye7eDD1fTmBSCHX1uo5j/1OGvb56DbSOMul79xHg8T6/zzGz35vZs2Z2SQj19Pe3y5T1dQmwz90b+kwb9fV13PYhbd+xXAgA62daqOe+mlkF8GPgVnc/BHwTmAcsAZrpaYKOtje6+/nAO4A/M7PlIdTQLzMrAq4C/jOYlAnr61Qy4ntnZncACeDfg0nNwEx3Xwp8CnjQzMaPYkkD/e0yYn0Bf8ixOxqjvr762T4M+NJ+pg1pneVCADQCM/r8XgfsCakWzKyQnj/uv7v7wwDuvs/dk+6eAr5Nmpq+J+Pue4J/9wOPBDXsM7OpQd1Tgf2jXVfgHcBL7r4vqDH09dXHQOso9O+dmd0IXAlc70GncdBdcCB4vIaefuMFo1XTSf52mbC+CoB3Az/snTba66u/7QNp/I7lQgC8CMw3sznBnuR1wM/CKCToX/wusMnd/7HP9Kl9XnYtsOH496a5rnIzG9f7mJ4DiBvoWU83Bi+7EfjpaNbVxzF7ZWGvr+MMtI5+BlxnZsVmNgeYD6waraLM7HLg08BV7h7pM73WzPKDx3ODuraPYl0D/e1CXV+By4DN7t7YO2E019dA2wfS+R0bjaPbYf8AV9BzRH0bcEeIdVxMTxNtPbA2+LkC+Dfg5WD6z4Cpo1zXXHrOJlgHvNK7joBq4GmgIfi3KoR1VgYcACr7TAtlfdETQs1AnJ69rz852ToC7gi+c1uAd4xyXa/S0z/c+z27L3jte4K/8TrgJeBdo1zXgH+7MNdXMP37wE3HvXY019dA24e0fcc0FISISI7KhS4gERHphwJARCRHKQBERHKUAkBEJEcpAEREcpQCQEQkRykARERyVEHYBYhkCjP7HHA9PRdQtQJrgIPACnqGEn8V+GN3j5jZ94EuYCE9Q1R/mJ6rNC8CfufuHwrm+TbgLnqG7N0GfNjdj5jZF+gZ3ygBPOHut4/SxxQ5Si0AEcDM6um56nMpPePB1AdPPezur3P38+gZnvdP+rxtIvAW4DbgUeArwNnAuWa2xMxqgM8Cl3nPQHurgU+ZWRU9wyCc7e6Lgb9P+wcU6YdaACI9LgZ+6u5dAGb2aDD9HDP7e2ACUAH8d5/3POrubmYv0zOE8MvBe1+h50YidfTctON/eoZ5oQj4DXAIiALfMbOfA4+l96OJ9E8BINKjv6F1oWd8mGvcfZ2ZfQh4c5/nuoN/U30e9/5eACSBJ939D09YmNkyem5ycx1wCz0tCZFRpS4gkR4vAO8ys5JgPPZ3BtPHAc3BML3XD3GevwXeaGZnAJhZmZktCOZf6e6/AG6lZ2x8kVGnFoAI4O4vmtnP6Bn1cRc9/fUHgc/Rc1emXfSMYjluCPNsCVoND5lZcTD5s8Bh4KdmVkJPy+O2kfocIkOh0UBFAmZWEZyhUwY8B6zw4B6tItlILQCR/7PSzM4CSoAfaOMv2U4tABGRHKWDwCIiOUoBICKSoxQAIiI5SgEgIpKjFAAiIjnq/wP7Epz6WCGGTAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(reward_memory, color='c', label='reward')\n",
    "plt.ylabel('avg reward')\n",
    "plt.xlabel('games')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
